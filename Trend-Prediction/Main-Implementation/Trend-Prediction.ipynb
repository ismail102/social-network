{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "pkl_file = \"/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/model_save/trend_pred\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/DataSet/trend_data/trend_emotion_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "trends = [\"approval\",\"toxic\",\"obscene\",\"threat\",\"hate\", \"offensive\", \"neutral\"]\n",
    "def one_hot_encoder(df):\n",
    "    one_hot_encoding = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        temp = [0]*7\n",
    "        labels = df.iloc[i][\"trend_type\"][1:-2].split(', ')\n",
    "        # print(labels)\n",
    "        for label in labels:\n",
    "            # print(label.replace('\\'', ''))\n",
    "            idx = trends.index(label.replace('\\'', ''))\n",
    "            temp[idx] = 1\n",
    "        one_hot_encoding.append(temp)\n",
    "    return pd.DataFrame(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110209/110209 [00:06<00:00, 16753.29it/s]\n"
     ]
    }
   ],
   "source": [
    "ohe_labels = one_hot_encoder(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurs = dataset.iloc[:, 1:-7]\n",
    "target = dataset.iloc[:, -7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(featurs, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous-multioutput'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-Prediction.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-Prediction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-Prediction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m randomForest \u001b[39m=\u001b[39m RandomForestClassifier(criterion\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m'\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_features\u001b[39m=\u001b[39m\u001b[39m28\u001b[39m, max_leaf_nodes\u001b[39m=\u001b[39m\u001b[39m19\u001b[39m, min_samples_leaf\u001b[39m=\u001b[39m\u001b[39m28\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-Prediction.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m randomForest\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:371\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    365\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSum of y is not strictly positive which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis necessary for Poisson regression.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m         )\n\u001b[1;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 371\u001b[0m y, expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_y_class_weight(y)\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(y, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m DOUBLE \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m y\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous:\n\u001b[1;32m    374\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(y, dtype\u001b[39m=\u001b[39mDOUBLE)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:758\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_y_class_weight\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m--> 758\u001b[0m     check_classification_targets(y)\n\u001b[1;32m    760\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[1;32m    761\u001b[0m     expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    192\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[1;32m    194\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    199\u001b[0m ]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous-multioutput'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "randomForest = RandomForestClassifier(criterion='entropy', max_depth=None, max_features=28, max_leaf_nodes=19, min_samples_leaf=28)\n",
    "randomForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randomForest.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pickle = pkl.dump(randomForest, open(os.path.join(pkl_file, 'random_forest.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_pkl = pkl.load(open(os.path.join(pkl_file, 'random_forest.pickle'), 'rb'))\n",
    "# y_pred = rf_pkl.predict(X_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr_y = classification_report(y_test, y_pred)\n",
    "print(cr_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(f\"Predicted response:\\n{y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pickle = pkl.dump(lr, open(os.path.join(pkl_file, 'linear_reg.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_pkl = pkl.load(open(os.path.join(pkl_file, 'linear_reg.pickle'), 'rb'))\n",
    "y_pred = lg_pkl.predict(X_test)\n",
    "print(f\"Predicted response:\\n{y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = lr.score(X_train, y_train) # Getting model score for test dataset\n",
    "print(f\"Model Score:\\n{r_squared}\") # Showing the model score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "log_reg = ClassifierChain(LogisticRegression(C= 0.001, penalty= 'l2'))\n",
    "# print(log_reg.get_params().keys())\n",
    "# Training logistic regression model on train data\n",
    "log_reg.fit(X_train, y_train)\n",
    "# predict\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(y_pred[0])\n",
    "# accuracy\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "# define model\n",
    "grid={\"classifier__C\": np.logspace(-3,3,7), \"classifier__penalty\": [\"l1\",\"l2\"]} # l1 lasso l2 ridge\n",
    "logreg = ClassifierChain(LogisticRegression())\n",
    "logreg_cv = GridSearchCV(logreg, grid, cv=5)\n",
    "# define search\n",
    "result = logreg_cv.fit(X_train, y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pickle = pkl.dump(log_reg, open(os.path.join(pkl_file, 'log_reg.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lg_pkl = pkl.load(open(os.path.join(pkl_file, 'log_reg.pickle'), 'rb'))\n",
    "y_pred = lg_pkl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr_y = classification_report(y_test, y_pred)\n",
    "print(cr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# initialize label powerset multi-label classifier\n",
    "# classifier = LabelPowerset(LogisticRegression())\n",
    "grid={\"classifier__C\": np.logspace(-3,3,7), \"classifier__penalty\": [\"l1\",\"l2\"]} # l1 lasso l2 ridge\n",
    "logreg1 = LabelPowerset(LogisticRegression())\n",
    "print(logreg1.get_params().keys())\n",
    "logreg_cv = GridSearchCV(logreg, grid, cv=5)\n",
    "# train\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "# predict\n",
    "predictions = logreg_cv.predict(X_test)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skmultilearn.adapt import MLkNN\n",
    "# from scipy.sparse import csr_matrix, lil_matrix\n",
    "# classifier_new = MLkNN(k=10)\n",
    "# # Note that this classifier can throw up errors when handling sparse matrices.\n",
    "# x_train = lil_matrix(X_train).toarray()\n",
    "# y_train = lil_matrix(y_train).toarray()\n",
    "# x_test = lil_matrix(X_test).toarray()\n",
    "# # train\n",
    "# classifier_new.fit(X_train, y_train)\n",
    "# # predict\n",
    "# predictions_new = classifier_new.predict(x_test)\n",
    "# # accuracy\n",
    "# print(\"Accuracy = \",accuracy_score(y_test,predictions_new))\n",
    "# print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # defining parameter range \n",
    "param_grid={\"estimator__C\": np.logspace(-3,3,7), \"estimator__penalty\": [\"l1\",\"l2\"]} # l1 lasso l2 ridge\n",
    "\n",
    "ln_svc = LinearSVC(random_state=42)\n",
    "multilabel_classifier = MultiOutputClassifier(estimator=ln_svc, n_jobs=-1)\n",
    "print(multilabel_classifier.get_params().keys())\n",
    "\n",
    "   \n",
    "grid = GridSearchCV(multilabel_classifier, param_grid, verbose = 2, cv=5) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train)\n",
    " \n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "param_grid={\"estimator__C\": np.logspace(-3,3,7), \"estimator__penalty\": [\"l1\",\"l2\"]} # l1 lasso l2 ridge\n",
    "ln_svc = LinearSVC(random_state=42)\n",
    "svmClassifier = OneVsRestClassifier(ln_svc, n_jobs=-1)\n",
    "print(svmClassifier.get_params().keys())\n",
    "\n",
    "grid = GridSearchCV(svmClassifier, param_grid, verbose = 2, cv=5) \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train)\n",
    " \n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "powerSetSVC = LabelPowerset(LinearSVC())\n",
    "print(svmClassifier.get_params().keys())\n",
    "powerSetSVC.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "boostClassifier = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "boostClassifier.fit(X_train, y_train)\n",
    "boostPreds = boostClassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, boostPreds)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "params = {'classifier__alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "          'classifier__fit_prior': [True, False],\n",
    "          'classifier__class_prior': [None, [0.1,]*(7) ]\n",
    "         }\n",
    "nb_classifier = BinaryRelevance(MultinomialNB())\n",
    "print(nb_classifier.get_params().keys())\n",
    "\n",
    "multinomial_nb_grid = GridSearchCV(nb_classifier, param_grid=params, n_jobs=-1, cv=10, verbose=1)\n",
    "# train\n",
    "multinomial_nb_grid.fit(X_train, y_train)\n",
    "# predict\n",
    "y_pred = multinomial_nb_grid.predict(X_test)\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pickle = pkl.dump(multinomial_nb_grid, open(os.path.join(pkl_file, 'naive_bayes.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr_y = classification_report(y_test, y_pred)\n",
    "print(cr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "nb_classifier = ClassifierChain(MultinomialNB())\n",
    "print(nb_classifier.get_params().keys())\n",
    "\n",
    "multinomial_nb_grid = GridSearchCV(nb_classifier, param_grid=params, n_jobs=-1, cv=10, verbose=1)\n",
    "\n",
    "# train\n",
    "multinomial_nb_grid.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = multinomial_nb_grid.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "nb_classifier = LabelPowerset(MultinomialNB())\n",
    "\n",
    "print(nb_classifier.get_params().keys())\n",
    "\n",
    "multinomial_nb_grid = GridSearchCV(nb_classifier, param_grid=params, n_jobs=-1, cv=10, verbose=1)\n",
    "\n",
    "# train\n",
    "multinomial_nb_grid.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = multinomial_nb_grid.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "grid_search  = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pickle = pkl.dump(grid_search, open(os.path.join(pkl_file, 'random_forest_grid.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: ', np.mean(errors))\n",
    "    print('Accuracy = ', accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "yhat = best_grid.predict(X_test)\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: \", acc)\n",
    "cr_y = classification_report(y_test, yhat)\n",
    "print(cr_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultiOutputClassifier(XGBClassifier())\n",
    "\n",
    "clf = Pipeline([('classify', classifier)]) \n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training Acc: \",clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pickle = pkl.dump(clf, open(os.path.join(pkl_file, 'xgb_classifier.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_y1 = classification_report(y_test, yhat)\n",
    "print(cr_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write code to calculate the R squared error\n",
    "# from sklearn.metrics import r2_score\n",
    "# r_squared_score = r2_score(y_test, y_pred) # Calculating model R^2 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view R-squared value\n",
    "# print(f\"R squared error:\\n{r_squared_score}\") # Showing the R squared error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label-Classification using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mlp for multi-label classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    " model = Sequential()\n",
    " model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    " model.add(Dense(n_outputs, activation='sigmoid'))\n",
    " model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "    # enumerate folds\n",
    "    # for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "    # X_train, X_test = X[train_ix], X[test_ix]\n",
    "    # y_train, y_test = y[train_ix], y[test_ix]\n",
    "    # define model\n",
    "    model = get_model(n_inputs, n_outputs)\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train, verbose=1, epochs=10)\n",
    "\n",
    "    pickle = pkl.dump(model, open(os.path.join(pkl_file, 'mlp_classifier.pickle'), 'wb'))\n",
    "    # make a prediction on the test set\n",
    "    yhat = model.predict(X_test)\n",
    "    # round probabilities to class labels\n",
    "    yhat = yhat.round()\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    # store result\n",
    "    print('>%.3f' % acc)\n",
    "    # results.append(acc)\n",
    "    return acc, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# X, y = get_dataset()\n",
    "# evaluate model\n",
    "acc, yhat = evaluate_model(X_train, y_train)\n",
    "# summarize performance\n",
    "# print('Accuracy: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_y = classification_report(y_test, yhat)\n",
    "print(cr_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
