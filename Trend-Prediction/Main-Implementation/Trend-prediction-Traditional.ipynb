{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:46.030183Z","iopub.status.busy":"2023-12-05T02:49:46.029776Z","iopub.status.idle":"2023-12-05T02:49:46.037631Z","shell.execute_reply":"2023-12-05T02:49:46.035849Z","shell.execute_reply.started":"2023-12-05T02:49:46.030151Z"},"trusted":true},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LinearRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import svm\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, multilabel_confusion_matrix\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import pandas as pd\n","import pickle as pkl\n","pkl_file = \"/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/model_save/trend_pred\""]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:46.047345Z","iopub.status.busy":"2023-12-05T02:49:46.046115Z","iopub.status.idle":"2023-12-05T02:49:46.055623Z","shell.execute_reply":"2023-12-05T02:49:46.054463Z","shell.execute_reply.started":"2023-12-05T02:49:46.047291Z"},"trusted":true},"outputs":[],"source":["from sklearn.datasets import make_multilabel_classification\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.metrics import make_scorer, f1_score, hamming_loss, log_loss\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:46.060904Z","iopub.status.busy":"2023-12-05T02:49:46.060533Z","iopub.status.idle":"2023-12-05T02:49:46.073804Z","shell.execute_reply":"2023-12-05T02:49:46.072743Z","shell.execute_reply.started":"2023-12-05T02:49:46.060870Z"},"trusted":true},"outputs":[],"source":["dataset = pd.read_csv('/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/DataSet/trend-data/emotion_trend_mapping(updated-D4).csv')"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>trend_type</th>\n","      <th>admiration</th>\n","      <th>amusement</th>\n","      <th>anger</th>\n","      <th>annoyance</th>\n","      <th>approval</th>\n","      <th>caring</th>\n","      <th>confusion</th>\n","      <th>...</th>\n","      <th>surprise</th>\n","      <th>neutral</th>\n","      <th>approval.1</th>\n","      <th>toxic</th>\n","      <th>obscene</th>\n","      <th>insult</th>\n","      <th>threat</th>\n","      <th>hate</th>\n","      <th>offensive</th>\n","      <th>neither</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Dear Jesus Really Vander Plaats really become ...</td>\n","      <td>['toxic', 'obscene', 'insult', 'hate']</td>\n","      <td>0.040463</td>\n","      <td>0.001738</td>\n","      <td>0.006114</td>\n","      <td>0.025908</td>\n","      <td>0.051705</td>\n","      <td>0.006283</td>\n","      <td>0.067305</td>\n","      <td>...</td>\n","      <td>0.006851</td>\n","      <td>0.189996</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>attack queers sorry Cabal Sanctimonious Hypocr...</td>\n","      <td>['neither']</td>\n","      <td>0.001806</td>\n","      <td>0.001375</td>\n","      <td>0.336123</td>\n","      <td>0.317506</td>\n","      <td>0.012453</td>\n","      <td>0.002173</td>\n","      <td>0.006411</td>\n","      <td>...</td>\n","      <td>0.002444</td>\n","      <td>0.133335</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Unspecified source ImageNanaJPG Thanks uploadi...</td>\n","      <td>['neither']</td>\n","      <td>0.000987</td>\n","      <td>0.000774</td>\n","      <td>0.034833</td>\n","      <td>0.036450</td>\n","      <td>0.004978</td>\n","      <td>0.001220</td>\n","      <td>0.017123</td>\n","      <td>...</td>\n","      <td>0.002954</td>\n","      <td>0.821627</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>person status where status abstract concept wi...</td>\n","      <td>['obscene']</td>\n","      <td>0.001493</td>\n","      <td>0.000768</td>\n","      <td>0.528994</td>\n","      <td>0.254255</td>\n","      <td>0.010222</td>\n","      <td>0.004622</td>\n","      <td>0.015273</td>\n","      <td>...</td>\n","      <td>0.001391</td>\n","      <td>0.092313</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>National Cunt Prevention Board name Norman fro...</td>\n","      <td>['toxic', 'obscene', 'insult']</td>\n","      <td>0.009913</td>\n","      <td>0.000559</td>\n","      <td>0.019684</td>\n","      <td>0.045652</td>\n","      <td>0.024483</td>\n","      <td>0.008476</td>\n","      <td>0.114395</td>\n","      <td>...</td>\n","      <td>0.006786</td>\n","      <td>0.532468</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 39 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0                                               text  \\\n","0           0  Dear Jesus Really Vander Plaats really become ...   \n","1           1  attack queers sorry Cabal Sanctimonious Hypocr...   \n","2           2  Unspecified source ImageNanaJPG Thanks uploadi...   \n","3           3  person status where status abstract concept wi...   \n","4           4  National Cunt Prevention Board name Norman fro...   \n","\n","                               trend_type  admiration  amusement     anger  \\\n","0  ['toxic', 'obscene', 'insult', 'hate']    0.040463   0.001738  0.006114   \n","1                             ['neither']    0.001806   0.001375  0.336123   \n","2                             ['neither']    0.000987   0.000774  0.034833   \n","3                             ['obscene']    0.001493   0.000768  0.528994   \n","4          ['toxic', 'obscene', 'insult']    0.009913   0.000559  0.019684   \n","\n","   annoyance  approval    caring  confusion  ...  surprise   neutral  \\\n","0   0.025908  0.051705  0.006283   0.067305  ...  0.006851  0.189996   \n","1   0.317506  0.012453  0.002173   0.006411  ...  0.002444  0.133335   \n","2   0.036450  0.004978  0.001220   0.017123  ...  0.002954  0.821627   \n","3   0.254255  0.010222  0.004622   0.015273  ...  0.001391  0.092313   \n","4   0.045652  0.024483  0.008476   0.114395  ...  0.006786  0.532468   \n","\n","   approval.1  toxic  obscene  insult  threat  hate  offensive  neither  \n","0         0.0    1.0      1.0     1.0     0.0   1.0        0.0        0  \n","1         0.0    0.0      0.0     0.0     0.0   0.0        0.0        1  \n","2         0.0    0.0      0.0     0.0     0.0   0.0        0.0        1  \n","3         0.0    0.0      1.0     0.0     0.0   0.0        0.0        0  \n","4         0.0    1.0      1.0     1.0     0.0   0.0        0.0        0  \n","\n","[5 rows x 39 columns]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["dataset.head()"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["(29853, 39)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["dataset.shape"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:47.130093Z","iopub.status.busy":"2023-12-05T02:49:47.129733Z","iopub.status.idle":"2023-12-05T02:49:47.147532Z","shell.execute_reply":"2023-12-05T02:49:47.145986Z","shell.execute_reply.started":"2023-12-05T02:49:47.130057Z"},"trusted":true},"outputs":[],"source":["dataset.drop(['Unnamed: 0'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["high_corr_features = ['admiration', 'anger', 'annoyance', 'approval', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', \n","                      'disgust', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'nervousness', 'neutral', 'optimism', 'pride', 'realization', \n","                      'relief', 'remorse', 'sadness']\n","# print(high_corr_features)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:47.150390Z","iopub.status.busy":"2023-12-05T02:49:47.148937Z","iopub.status.idle":"2023-12-05T02:49:47.182855Z","shell.execute_reply":"2023-12-05T02:49:47.181587Z","shell.execute_reply.started":"2023-12-05T02:49:47.150334Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>trend_type</th>\n","      <th>admiration</th>\n","      <th>amusement</th>\n","      <th>anger</th>\n","      <th>annoyance</th>\n","      <th>approval</th>\n","      <th>caring</th>\n","      <th>confusion</th>\n","      <th>curiosity</th>\n","      <th>...</th>\n","      <th>surprise</th>\n","      <th>neutral</th>\n","      <th>approval.1</th>\n","      <th>toxic</th>\n","      <th>obscene</th>\n","      <th>insult</th>\n","      <th>threat</th>\n","      <th>hate</th>\n","      <th>offensive</th>\n","      <th>neither</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dear Jesus Really Vander Plaats really become ...</td>\n","      <td>['toxic', 'obscene', 'insult', 'hate']</td>\n","      <td>0.040463</td>\n","      <td>0.001738</td>\n","      <td>0.006114</td>\n","      <td>0.025908</td>\n","      <td>0.051705</td>\n","      <td>0.006283</td>\n","      <td>0.067305</td>\n","      <td>0.497370</td>\n","      <td>...</td>\n","      <td>0.006851</td>\n","      <td>0.189996</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>attack queers sorry Cabal Sanctimonious Hypocr...</td>\n","      <td>['neither']</td>\n","      <td>0.001806</td>\n","      <td>0.001375</td>\n","      <td>0.336123</td>\n","      <td>0.317506</td>\n","      <td>0.012453</td>\n","      <td>0.002173</td>\n","      <td>0.006411</td>\n","      <td>0.005952</td>\n","      <td>...</td>\n","      <td>0.002444</td>\n","      <td>0.133335</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Unspecified source ImageNanaJPG Thanks uploadi...</td>\n","      <td>['neither']</td>\n","      <td>0.000987</td>\n","      <td>0.000774</td>\n","      <td>0.034833</td>\n","      <td>0.036450</td>\n","      <td>0.004978</td>\n","      <td>0.001220</td>\n","      <td>0.017123</td>\n","      <td>0.024646</td>\n","      <td>...</td>\n","      <td>0.002954</td>\n","      <td>0.821627</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>person status where status abstract concept wi...</td>\n","      <td>['obscene']</td>\n","      <td>0.001493</td>\n","      <td>0.000768</td>\n","      <td>0.528994</td>\n","      <td>0.254255</td>\n","      <td>0.010222</td>\n","      <td>0.004622</td>\n","      <td>0.015273</td>\n","      <td>0.015281</td>\n","      <td>...</td>\n","      <td>0.001391</td>\n","      <td>0.092313</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>National Cunt Prevention Board name Norman fro...</td>\n","      <td>['toxic', 'obscene', 'insult']</td>\n","      <td>0.009913</td>\n","      <td>0.000559</td>\n","      <td>0.019684</td>\n","      <td>0.045652</td>\n","      <td>0.024483</td>\n","      <td>0.008476</td>\n","      <td>0.114395</td>\n","      <td>0.045156</td>\n","      <td>...</td>\n","      <td>0.006786</td>\n","      <td>0.532468</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 38 columns</p>\n","</div>"],"text/plain":["                                                text  \\\n","0  Dear Jesus Really Vander Plaats really become ...   \n","1  attack queers sorry Cabal Sanctimonious Hypocr...   \n","2  Unspecified source ImageNanaJPG Thanks uploadi...   \n","3  person status where status abstract concept wi...   \n","4  National Cunt Prevention Board name Norman fro...   \n","\n","                               trend_type  admiration  amusement     anger  \\\n","0  ['toxic', 'obscene', 'insult', 'hate']    0.040463   0.001738  0.006114   \n","1                             ['neither']    0.001806   0.001375  0.336123   \n","2                             ['neither']    0.000987   0.000774  0.034833   \n","3                             ['obscene']    0.001493   0.000768  0.528994   \n","4          ['toxic', 'obscene', 'insult']    0.009913   0.000559  0.019684   \n","\n","   annoyance  approval    caring  confusion  curiosity  ...  surprise  \\\n","0   0.025908  0.051705  0.006283   0.067305   0.497370  ...  0.006851   \n","1   0.317506  0.012453  0.002173   0.006411   0.005952  ...  0.002444   \n","2   0.036450  0.004978  0.001220   0.017123   0.024646  ...  0.002954   \n","3   0.254255  0.010222  0.004622   0.015273   0.015281  ...  0.001391   \n","4   0.045652  0.024483  0.008476   0.114395   0.045156  ...  0.006786   \n","\n","    neutral  approval.1  toxic  obscene  insult  threat  hate  offensive  \\\n","0  0.189996         0.0    1.0      1.0     1.0     0.0   1.0        0.0   \n","1  0.133335         0.0    0.0      0.0     0.0     0.0   0.0        0.0   \n","2  0.821627         0.0    0.0      0.0     0.0     0.0   0.0        0.0   \n","3  0.092313         0.0    0.0      1.0     0.0     0.0   0.0        0.0   \n","4  0.532468         0.0    1.0      1.0     1.0     0.0   0.0        0.0   \n","\n","   neither  \n","0        0  \n","1        1  \n","2        1  \n","3        0  \n","4        0  \n","\n","[5 rows x 38 columns]"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["dataset.head()"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:47.187522Z","iopub.status.busy":"2023-12-05T02:49:47.187184Z","iopub.status.idle":"2023-12-05T02:49:47.202716Z","shell.execute_reply":"2023-12-05T02:49:47.201374Z","shell.execute_reply.started":"2023-12-05T02:49:47.187494Z"},"trusted":true},"outputs":[],"source":["featurs = dataset.iloc[:, 2:-8]\n","target = dataset.iloc[:, -8:]"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:47.204536Z","iopub.status.busy":"2023-12-05T02:49:47.204136Z","iopub.status.idle":"2023-12-05T02:49:47.233592Z","shell.execute_reply":"2023-12-05T02:49:47.232540Z","shell.execute_reply.started":"2023-12-05T02:49:47.204500Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>admiration</th>\n","      <th>amusement</th>\n","      <th>anger</th>\n","      <th>annoyance</th>\n","      <th>approval</th>\n","      <th>caring</th>\n","      <th>confusion</th>\n","      <th>curiosity</th>\n","      <th>desire</th>\n","      <th>disappointment</th>\n","      <th>...</th>\n","      <th>love</th>\n","      <th>nervousness</th>\n","      <th>optimism</th>\n","      <th>pride</th>\n","      <th>realization</th>\n","      <th>relief</th>\n","      <th>remorse</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>neutral</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.040463</td>\n","      <td>0.001738</td>\n","      <td>0.006114</td>\n","      <td>0.025908</td>\n","      <td>0.051705</td>\n","      <td>0.006283</td>\n","      <td>0.067305</td>\n","      <td>0.497370</td>\n","      <td>0.013709</td>\n","      <td>0.004352</td>\n","      <td>...</td>\n","      <td>0.000502</td>\n","      <td>0.000344</td>\n","      <td>0.027791</td>\n","      <td>0.007960</td>\n","      <td>0.021605</td>\n","      <td>0.001311</td>\n","      <td>0.000575</td>\n","      <td>0.000499</td>\n","      <td>0.006851</td>\n","      <td>0.189996</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.001806</td>\n","      <td>0.001375</td>\n","      <td>0.336123</td>\n","      <td>0.317506</td>\n","      <td>0.012453</td>\n","      <td>0.002173</td>\n","      <td>0.006411</td>\n","      <td>0.005952</td>\n","      <td>0.000429</td>\n","      <td>0.013386</td>\n","      <td>...</td>\n","      <td>0.000169</td>\n","      <td>0.001365</td>\n","      <td>0.001365</td>\n","      <td>0.000586</td>\n","      <td>0.005943</td>\n","      <td>0.000414</td>\n","      <td>0.000987</td>\n","      <td>0.002704</td>\n","      <td>0.002444</td>\n","      <td>0.133335</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000987</td>\n","      <td>0.000774</td>\n","      <td>0.034833</td>\n","      <td>0.036450</td>\n","      <td>0.004978</td>\n","      <td>0.001220</td>\n","      <td>0.017123</td>\n","      <td>0.024646</td>\n","      <td>0.000479</td>\n","      <td>0.003308</td>\n","      <td>...</td>\n","      <td>0.000126</td>\n","      <td>0.000342</td>\n","      <td>0.000519</td>\n","      <td>0.000565</td>\n","      <td>0.002335</td>\n","      <td>0.000198</td>\n","      <td>0.000371</td>\n","      <td>0.001146</td>\n","      <td>0.002954</td>\n","      <td>0.821627</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.001493</td>\n","      <td>0.000768</td>\n","      <td>0.528994</td>\n","      <td>0.254255</td>\n","      <td>0.010222</td>\n","      <td>0.004622</td>\n","      <td>0.015273</td>\n","      <td>0.015281</td>\n","      <td>0.000821</td>\n","      <td>0.005845</td>\n","      <td>...</td>\n","      <td>0.000187</td>\n","      <td>0.000658</td>\n","      <td>0.002404</td>\n","      <td>0.000674</td>\n","      <td>0.003863</td>\n","      <td>0.000325</td>\n","      <td>0.000800</td>\n","      <td>0.001137</td>\n","      <td>0.001391</td>\n","      <td>0.092313</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.009913</td>\n","      <td>0.000559</td>\n","      <td>0.019684</td>\n","      <td>0.045652</td>\n","      <td>0.024483</td>\n","      <td>0.008476</td>\n","      <td>0.114395</td>\n","      <td>0.045156</td>\n","      <td>0.007880</td>\n","      <td>0.010826</td>\n","      <td>...</td>\n","      <td>0.000190</td>\n","      <td>0.000956</td>\n","      <td>0.021486</td>\n","      <td>0.018226</td>\n","      <td>0.050623</td>\n","      <td>0.000810</td>\n","      <td>0.004485</td>\n","      <td>0.003249</td>\n","      <td>0.006786</td>\n","      <td>0.532468</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 28 columns</p>\n","</div>"],"text/plain":["   admiration  amusement     anger  annoyance  approval    caring  confusion  \\\n","0    0.040463   0.001738  0.006114   0.025908  0.051705  0.006283   0.067305   \n","1    0.001806   0.001375  0.336123   0.317506  0.012453  0.002173   0.006411   \n","2    0.000987   0.000774  0.034833   0.036450  0.004978  0.001220   0.017123   \n","3    0.001493   0.000768  0.528994   0.254255  0.010222  0.004622   0.015273   \n","4    0.009913   0.000559  0.019684   0.045652  0.024483  0.008476   0.114395   \n","\n","   curiosity    desire  disappointment  ...      love  nervousness  optimism  \\\n","0   0.497370  0.013709        0.004352  ...  0.000502     0.000344  0.027791   \n","1   0.005952  0.000429        0.013386  ...  0.000169     0.001365  0.001365   \n","2   0.024646  0.000479        0.003308  ...  0.000126     0.000342  0.000519   \n","3   0.015281  0.000821        0.005845  ...  0.000187     0.000658  0.002404   \n","4   0.045156  0.007880        0.010826  ...  0.000190     0.000956  0.021486   \n","\n","      pride  realization    relief   remorse   sadness  surprise   neutral  \n","0  0.007960     0.021605  0.001311  0.000575  0.000499  0.006851  0.189996  \n","1  0.000586     0.005943  0.000414  0.000987  0.002704  0.002444  0.133335  \n","2  0.000565     0.002335  0.000198  0.000371  0.001146  0.002954  0.821627  \n","3  0.000674     0.003863  0.000325  0.000800  0.001137  0.001391  0.092313  \n","4  0.018226     0.050623  0.000810  0.004485  0.003249  0.006786  0.532468  \n","\n","[5 rows x 28 columns]"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["featurs.head()"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>approval.1</th>\n","      <th>toxic</th>\n","      <th>obscene</th>\n","      <th>insult</th>\n","      <th>threat</th>\n","      <th>hate</th>\n","      <th>offensive</th>\n","      <th>neither</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   approval.1  toxic  obscene  insult  threat  hate  offensive  neither\n","0         0.0    1.0      1.0     1.0     0.0   1.0        0.0        0\n","1         0.0    0.0      0.0     0.0     0.0   0.0        0.0        1\n","2         0.0    0.0      0.0     0.0     0.0   0.0        0.0        1\n","3         0.0    0.0      1.0     0.0     0.0   0.0        0.0        0\n","4         0.0    1.0      1.0     1.0     0.0   0.0        0.0        0"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["target.head()"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:47.234991Z","iopub.status.busy":"2023-12-05T02:49:47.234671Z","iopub.status.idle":"2023-12-05T02:49:47.297404Z","shell.execute_reply":"2023-12-05T02:49:47.295182Z","shell.execute_reply.started":"2023-12-05T02:49:47.234950Z"},"trusted":true},"outputs":[],"source":["# Splitting the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(featurs, target, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# from sklearn.preprocessing import StandardScaler\n","# scaler = StandardScaler()\n","\n","# # Fit the scaler on the training data and transform the features\n","# X_train= scaler.fit_transform(X_train)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:47.300231Z","iopub.status.busy":"2023-12-05T02:49:47.299396Z","iopub.status.idle":"2023-12-05T02:49:47.308092Z","shell.execute_reply":"2023-12-05T02:49:47.305840Z","shell.execute_reply.started":"2023-12-05T02:49:47.299899Z"},"trusted":true},"outputs":[],"source":["# Create a scoring function\n","scoring = {\n","    'F1 Micro': make_scorer(f1_score, average='micro'),\n","    'Loss': make_scorer(log_loss)\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## RandomForest"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:47.310606Z","iopub.status.busy":"2023-12-05T02:49:47.310182Z","iopub.status.idle":"2023-12-05T02:49:47.323915Z","shell.execute_reply":"2023-12-05T02:49:47.322084Z","shell.execute_reply.started":"2023-12-05T02:49:47.310562Z"},"trusted":true},"outputs":[],"source":["# from sklearn.model_selection import GridSearchCV\n","# # Create the parameter grid based on the results of random search \n","# params = {\n","#     'n_estimators': [50, 100],\n","#     'max_depth': [None, 10, 20]\n","# }\n","# rf = RandomForestClassifier()\n","# rmd_forest_grid = GridSearchCV(estimator = rf, param_grid = params, cv = 2, scoring=scoring, refit='F1 Micro', n_jobs = -1, verbose=2)\n","# # train\n","# rmd_forest_grid.fit(X_train, y_train)\n","# # predict\n","# grid_pred = rmd_forest_grid.predict(X_test)\n","# print(\"Accuracy = \", accuracy_score(y_test, grid_pred))"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["from sklearn.datasets import make_multilabel_classification\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import make_scorer, hamming_loss\n","from sklearn.tree import DecisionTreeClassifier"]},{"cell_type":"markdown","metadata":{},"source":["# **XGBoost Classifier with MultiOutputClassifier and GridSearch**"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:49:47.326937Z","iopub.status.busy":"2023-12-05T02:49:47.326593Z","iopub.status.idle":"2023-12-05T02:51:15.019710Z","shell.execute_reply":"2023-12-05T02:51:15.017998Z","shell.execute_reply.started":"2023-12-05T02:49:47.326905Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END learning_rate=0.1, max_depth=10, n_estimators=700, objective=binary:logistic; total time=11.5min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=700, objective=binary:logistic; total time=11.5min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=700, objective=binary:logistic; total time=11.5min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=700, objective=binary:logistic; total time=11.5min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=700, objective=binary:logistic; total time=11.8min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=1000, objective=binary:logistic; total time=16.2min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=1000, objective=binary:logistic; total time=16.2min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=1000, objective=binary:logistic; total time=16.2min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=1000, objective=binary:logistic; total time=16.2min\n","[CV] END learning_rate=0.1, max_depth=10, n_estimators=1000, objective=binary:logistic; total time=16.3min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=700, objective=binary:logistic; total time=20.6min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=700, objective=binary:logistic; total time=20.6min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=700, objective=binary:logistic; total time=20.6min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=700, objective=binary:logistic; total time=20.7min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=700, objective=binary:logistic; total time=21.1min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=1000, objective=binary:logistic; total time=28.7min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=1000, objective=binary:logistic; total time=28.8min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=1000, objective=binary:logistic; total time=28.8min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=1000, objective=binary:logistic; total time=28.9min\n","[CV] END learning_rate=0.1, max_depth=20, n_estimators=1000, objective=binary:logistic; total time=28.9min\n","Best parameters for XGBoost:\n","{'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 700, 'objective': 'binary:logistic'}\n","Classification report on test set:\n","[[[5371   88]\n","  [ 503    9]]\n","\n"," [[1367 1560]\n","  [1403 1641]]\n","\n"," [[3995  293]\n","  [1589   94]]\n","\n"," [[4141  239]\n","  [1519   72]]\n","\n"," [[5874   11]\n","  [  86    0]]\n","\n"," [[5312   90]\n","  [ 563    6]]\n","\n"," [[4958  134]\n","  [ 857   22]]\n","\n"," [[4755  151]\n","  [1030   35]]]\n"]}],"source":["\n","# Define the XGBoost classifier\n","xgb = XGBClassifier()\n","\n","# Parameters to tune for XGBoost\n","params_xgb = {\n","    'n_estimators': [1000],\n","    'max_depth': [15],\n","}\n","\n","# Define the parameter grid including learning rate and loss function\n","param_grid = {\n","    'learning_rate': [0.1],  # Adjust these values as needed\n","    'objective': ['binary:logistic'],  # Examples of loss functions\n","    # Other hyperparameters to tune\n","    'max_depth': [10, 20],\n","    'n_estimators': [700, 1000]\n","    # Add other parameters to optimize\n","}\n","\n","# Create the GridSearchCV for XGBoost\n","grid_search_xgb = GridSearchCV(xgb, param_grid, cv=5, verbose=2, n_jobs=-1)\n","grid_search_xgb.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters for XGBoost:\n","{'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 700, 'objective': 'binary:logistic'}\n","Classification report on test set:\n","[[[5371   88]\n","  [ 503    9]]\n","\n"," [[1367 1560]\n","  [1403 1641]]\n","\n"," [[3995  293]\n","  [1589   94]]\n","\n"," [[4141  239]\n","  [1519   72]]\n","\n"," [[5874   11]\n","  [  86    0]]\n","\n"," [[5312   90]\n","  [ 563    6]]\n","\n"," [[4958  134]\n","  [ 857   22]]\n","\n"," [[4755  151]\n","  [1030   35]]]\n"]}],"source":["print(\"Best parameters for XGBoost:\")\n","print(grid_search_xgb.best_params_)\n","\n","print(\"Classification report on test set:\")\n","y_pred_xgb = grid_search_xgb.predict(X_test)\n","print(multilabel_confusion_matrix(y_test, y_pred_xgb))"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Acc:  0.872414370655724\n"]}],"source":["print(\"Training Acc: \", grid_search_xgb.score(X_train, y_train))\n","# print(\"Test Acc: \", grid_search_xgb.score(X_test, y_test))"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/plain":["array([6.1769114e-04, 5.0359696e-01, 4.9137542e-01, 5.0174773e-01,\n","       4.9070087e-01, 4.9660531e-01, 3.7934605e-04, 9.6876064e-04],\n","      dtype=float32)"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["pred_proba = grid_search_xgb.predict_proba(X_train)\n","pred_proba[0]\n","# print(classification_report(y_test, pred_proba))"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["import os\n","pkl_file = \"/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/model_save/trend_pred\"\n","pickle = pkl.dump(grid_search_xgb, open(os.path.join(pkl_file, 'grid_xgb.pickle'), 'wb'))"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# import numpy as np\n","# from sklearn.datasets import make_classification\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.linear_model import LogisticRegression\n","# from sklearn.ensemble import StackingClassifier\n","# import xgboost as xgb\n","\n","# # Initialize base models\n","# base_models = [\n","#     ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n","#     ('lr', LogisticRegression(max_iter=1000, random_state=42))\n","# ]\n","\n","# # Initialize XGBoost model\n","# xgb_model = xgb.XGBClassifier(max_depth=15, n_estimators=200, learning_rate=0.1, random_state=42)\n","\n","# multilabel = MultiOutputClassifier(xgb_model)\n","\n","# # StackingClassifier with XGBoost as final_estimator\n","# stacking_model = StackingClassifier(estimators=base_models, final_estimator=multilabel)\n","\n","# # Fit the stacking model\n","# stacking_model.fit(X_train, y_train)\n","\n","# # Evaluate on test set\n","# accuracy = stacking_model.score(X_test, y_test)\n","# print(\"Accuracy on test set (Stacking):\", accuracy)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# pred_proba = stacking_model.predict_proba(X_test)\n","# print(\"Prediction Probability: \", pred_proba)\n","# # print(classification_report(y_test, pred_proba))"]},{"cell_type":"markdown","metadata":{},"source":["# **XGB Classifier with MultiOutputClassifier, Base Decision Tree and GridSearch**"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:51:16.693563Z","iopub.status.busy":"2023-12-05T02:51:16.693141Z","iopub.status.idle":"2023-12-05T02:53:48.030456Z","shell.execute_reply":"2023-12-05T02:53:48.029090Z","shell.execute_reply.started":"2023-12-05T02:51:16.693526Z"},"trusted":true},"outputs":[],"source":["\n","# # Define the XGBoost classifier\n","# xgb = MultiOutputClassifier(XGBClassifier(base_estimator=DecisionTreeClassifier(max_depth=3), n_estimators=100, random_state=42))\n","\n","# # Parameters to tune for XGBoost\n","# params_xgb = {\n","#     'estimator__base_estimator__max_depth': [5, 10, 15],\n","#     'estimator__n_estimators': [50, 100, 150],\n","#     'estimator__max_depth': [5, 10, 15]\n","# }\n","\n","# # Create the GridSearchCV for XGBoost\n","# grid_search_xgb = GridSearchCV(xgb, params_xgb, scoring=scoring, cv=2, refit='F1 Micro', verbose=2)\n","# grid_search_xgb.fit(X_train, y_train)\n","\n","# print(\"Best parameters for XGBoost:\")\n","# print(grid_search_xgb.best_params_)\n","\n","# print(\"Classification report on test set:\")\n","# y_pred_xgb = grid_search_xgb.predict(X_test)\n","# print(classification_report(y_test, y_pred_xgb))"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["# # Evaluate performance (you can use different metrics for multilabel classification)\n","# accuracy = accuracy_score(y_test, y_pred_xgb)\n","# print(f\"Accuracy: {accuracy}\")\n","# print(\"Training Acc: \", grid_search_xgb.score(X_train, y_train))\n","# print(\"Test Acc: \", grid_search_xgb.score(X_test, y_test))"]},{"cell_type":"markdown","metadata":{},"source":["# **AdaBoost Classifier with MultiOutputClassifier and GridSearch**"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T02:53:48.032922Z","iopub.status.busy":"2023-12-05T02:53:48.032423Z","iopub.status.idle":"2023-12-05T03:12:30.512189Z","shell.execute_reply":"2023-12-05T03:12:30.509955Z","shell.execute_reply.started":"2023-12-05T02:53:48.032869Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=700; total time=12.4min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=1000; total time=17.7min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.1, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=700; total time=12.4min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=700; total time=12.4min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=700; total time=12.4min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.3, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=700; total time=12.4min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=700; total time=12.4min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=700; total time=12.5min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=1000; total time=17.8min\n","[CV] END estimator__learning_rate=0.5, estimator__n_estimators=1000; total time=17.8min\n","Best parameters found:\n","{'estimator__learning_rate': 0.5, 'estimator__n_estimators': 1000}\n","Best score: 0.0027476355212020247\n"]}],"source":["# Create AdaBoost classifier\n","ada_classifier = AdaBoostClassifier(random_state=42)\n","\n","# Create MultiOutputClassifier using AdaBoost\n","multioutput_classifier = MultiOutputClassifier(ada_classifier)\n","\n","# Define the parameter grid for GridSearch\n","param_grid = {\n","    'estimator__n_estimators': [700, 1000],\n","    'estimator__learning_rate': [0.1, 0.3, 0.5]\n","}\n","\n","# Perform GridSearchCV\n","grid_search = GridSearchCV(multioutput_classifier, param_grid, scoring=scoring, cv=5, refit='F1 Micro', verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters and score\n","print(\"Best parameters found:\")\n","print(grid_search.best_params_)\n","print(\"Best score:\", grid_search.best_score_)\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"ename":"NotFittedError","evalue":"This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb Cell 29\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Evaluate on test set\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39;49mpredict_proba(X_test)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:522\u001b[0m, in \u001b[0;36mBaseSearchCV.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39m@available_if\u001b[39m(_estimator_has(\u001b[39m\"\u001b[39m\u001b[39mpredict_proba\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    503\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    504\u001b[0m     \u001b[39m\"\"\"Call predict_proba on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \n\u001b[1;32m    506\u001b[0m \u001b[39m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39m        to that in the fitted attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    523\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict_proba(X)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1345\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[1;32m   1341\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1342\u001b[0m     ]\n\u001b[1;32m   1344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n","\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."]}],"source":["# Evaluate on test set\n","y_pred = grid_search.predict_proba(X_test)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T03:12:30.514617Z","iopub.status.busy":"2023-12-05T03:12:30.514166Z","iopub.status.idle":"2023-12-05T03:12:30.532045Z","shell.execute_reply":"2023-12-05T03:12:30.530712Z","shell.execute_reply.started":"2023-12-05T03:12:30.514558Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.0014027119096920713\n","Training Acc:  0.00998461829074129\n","Test Acc:  0.0031290461804056972\n"]}],"source":["# Evaluate performance (you can use different metrics for multilabel classification)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","print(\"Training Acc: \", grid_search.score(X_train, y_train))\n","print(\"Test Acc: \", grid_search.score(X_test, y_test))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction Probability:  [array([[0.50056444, 0.49943556],\n","       [0.50058549, 0.49941451],\n","       [0.50056181, 0.49943819],\n","       ...,\n","       [0.5004702 , 0.4995298 ],\n","       [0.5005403 , 0.4994597 ],\n","       [0.50051319, 0.49948681]]), array([[0.50069239, 0.49930761],\n","       [0.50092554, 0.49907446],\n","       [0.50074948, 0.49925052],\n","       ...,\n","       [0.50069992, 0.49930008],\n","       [0.50063255, 0.49936745],\n","       [0.50071187, 0.49928813]]), array([[0.5010137 , 0.4989863 ],\n","       [0.50118454, 0.49881546],\n","       [0.50098471, 0.49901529],\n","       ...,\n","       [0.50101784, 0.49898216],\n","       [0.50096689, 0.49903311],\n","       [0.50109439, 0.49890561]]), array([[0.50109298, 0.49890702],\n","       [0.50129886, 0.49870114],\n","       [0.50117994, 0.49882006],\n","       ...,\n","       [0.50112853, 0.49887147],\n","       [0.50108662, 0.49891338],\n","       [0.50111298, 0.49888702]]), array([[0.50306489, 0.49693511],\n","       [0.50455038, 0.49544962],\n","       [0.51187922, 0.48812078],\n","       ...,\n","       [0.50344997, 0.49655003],\n","       [0.50314006, 0.49685994],\n","       [0.50501905, 0.49498095]]), array([[0.50166704, 0.49833296],\n","       [0.50144004, 0.49855996],\n","       [0.50176161, 0.49823839],\n","       ...,\n","       [0.50161966, 0.49838034],\n","       [0.50187104, 0.49812896],\n","       [0.50136638, 0.49863362]]), array([[0.50058123, 0.49941877],\n","       [0.50045579, 0.49954421],\n","       [0.50054925, 0.49945075],\n","       ...,\n","       [0.50058807, 0.49941193],\n","       [0.50046402, 0.49953598],\n","       [0.50062304, 0.49937696]]), array([[0.50049549, 0.49950451],\n","       [0.50050982, 0.49949018],\n","       [0.50042353, 0.49957647],\n","       ...,\n","       [0.50057371, 0.49942629],\n","       [0.50058263, 0.49941737],\n","       [0.50047161, 0.49952839]])]\n"]}],"source":["pred_proba = grid_search.predict_proba(X_test)\n","print(\"Prediction Probability: \", pred_proba)\n","# print(classification_report(y_test, pred_proba))"]},{"cell_type":"markdown","metadata":{},"source":["# **AdaBoost Classifier with Multi Output, Base Decision Tree, GridSearch**"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T03:12:35.407096Z","iopub.status.busy":"2023-12-05T03:12:35.405936Z","iopub.status.idle":"2023-12-05T06:56:13.253864Z","shell.execute_reply":"2023-12-05T06:56:13.252516Z","shell.execute_reply.started":"2023-12-05T03:12:35.407043Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 27 candidates, totalling 135 fits\n","[CV] END estimator__base_estimator__max_depth=15, estimator__learning_rate=0.01, estimator__n_estimators=500; total time=100.5min\n","[CV] END estimator__base_estimator__max_depth=15, estimator__learning_rate=0.01, estimator__n_estimators=500; total time=100.7min\n","[CV] END estimator__base_estimator__max_depth=15, estimator__learning_rate=0.01, estimator__n_estimators=500; total time=100.4min\n","[CV] END estimator__base_estimator__max_depth=15, estimator__learning_rate=0.01, estimator__n_estimators=500; total time=100.7min\n","[CV] END estimator__base_estimator__max_depth=15, estimator__learning_rate=0.01, estimator__n_estimators=500; total time=101.1min\n","[CV] END estimator__base_estimator__max_depth=15, estimator__learning_rate=0.01, estimator__n_estimators=700; total time=141.5min\n","[CV] END estimator__base_estimator__max_depth=15, estimator__learning_rate=0.01, estimator__n_estimators=700; total time=140.6min\n","[CV] END estimator__base_estimator__max_depth=15, estimator__learning_rate=0.01, estimator__n_estimators=700; total time=139.7min\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb Cell 32\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Create scorer for multilabel classification (use appropriate metric)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# scorer = make_scorer(log_loss)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Perform GridSearchCV\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(multioutput_classifier, param_grid, scoring\u001b[39m=\u001b[39mscoring, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, refit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mF1 Micro\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Get the best parameters and score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.100.192.118/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/Trend-prediction-Traditional.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest parameters found:\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/multioutput.py:435\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m    410\u001b[0m     \u001b[39m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, Y, sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m [estimator\u001b[39m.\u001b[39mclasses_ \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_]\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/multioutput.py:202\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnderlying estimator does not support sample weights.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m fit_params_validated \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m--> 202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    203\u001b[0m     delayed(_fit_estimator)(\n\u001b[1;32m    204\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y[:, i], sample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_validated\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m     \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(y\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mn_features_in_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_features_in_\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/multioutput.py:44\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     42\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m     43\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:506\u001b[0m, in \u001b[0;36mAdaBoostClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAlgorithm must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    505\u001b[0m \u001b[39m# Fit\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:160\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    156\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m iboost \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators):\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     sample_weight, estimator_weight, estimator_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost(\n\u001b[1;32m    161\u001b[0m         iboost, X, y, sample_weight, random_state\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Early termination\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:568\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[39mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:577\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m--> 577\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m    579\u001b[0m y_predict_proba \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    581\u001b[0m \u001b[39mif\u001b[39;00m iboost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    970\u001b[0m         X,\n\u001b[1;32m    971\u001b[0m         y,\n\u001b[1;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.datasets import make_multilabel_classification\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import make_scorer, hamming_loss\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Create AdaBoost classifier\n","ada_classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3), n_estimators=100, random_state=42)\n","\n","# Create MultiOutputClassifier using AdaBoost\n","multioutput_classifier = MultiOutputClassifier(ada_classifier)\n","\n","# Define the parameter grid for GridSearch\n","param_grid = {\n","    'estimator__base_estimator__max_depth': [15, 20, 25],\n","    'estimator__n_estimators': [500, 700, 1000],\n","    'estimator__learning_rate': [0.01, 0.1, 0.3]\n","}\n","\n","# Create scorer for multilabel classification (use appropriate metric)\n","# scorer = make_scorer(log_loss)\n","\n","# Perform GridSearchCV\n","grid_search = GridSearchCV(multioutput_classifier, param_grid, scoring=scoring, cv=5, refit='F1 Micro', verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters and score\n","print(\"Best parameters found:\")\n","print(grid_search.best_params_)\n","print(\"Best score:\", grid_search.best_score_)\n","\n","# Evaluate on test set\n","y_pred = grid_search.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T06:56:13.255399Z","iopub.status.busy":"2023-12-05T06:56:13.255107Z","iopub.status.idle":"2023-12-05T06:56:20.712646Z","shell.execute_reply":"2023-12-05T06:56:20.710959Z","shell.execute_reply.started":"2023-12-05T06:56:13.255373Z"},"trusted":true},"outputs":[],"source":["# Evaluate performance (you can use different metrics for multilabel classification)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","print(\"Training Acc: \", grid_search.score(X_train, y_train))\n","print(\"Test Acc: \", grid_search.score(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_proba = grid_search.predict_proba(X_test)\n","print(\"Prediction Probability: \", pred_proba)\n","# print(classification_report(y_test, pred_proba))"]},{"cell_type":"markdown","metadata":{},"source":["# **LGBM Classifier with MultiOutputClass, and GridSearch**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T06:56:20.716990Z","iopub.status.busy":"2023-12-05T06:56:20.716076Z","iopub.status.idle":"2023-12-05T07:02:11.955857Z","shell.execute_reply":"2023-12-05T07:02:11.954655Z","shell.execute_reply.started":"2023-12-05T06:56:20.716925Z"},"trusted":true},"outputs":[],"source":["from lightgbm import LGBMClassifier\n","# Define the classifier\n","lgbm = LGBMClassifier()\n","\n","# Create MultiOutputClassifier using AdaBoost\n","multioutput_classifier = MultiOutputClassifier(lgbm)\n","\n","# Define the parameters for grid search\n","param_grid = {\n","    'estimator__num_leaves': [20, 50],  # Vary the number of leaves\n","    'estimator__max_depth': [15,20,25],  # Vary the maximum depth of trees\n","    'estimator__n_estimators': [500, 700, 1000],  # Number of boosting iterations\n","    'estimator__learning_rate': [0.01, 0.1, 0.3]  # Learning rate for boosting\n","}\n","\n","# Create a scoring function\n","# scoring = {\n","#     'F1 Micro': make_scorer(f1_score, average='micro'),\n","#     'Hamming Loss': make_scorer(hamming_loss)\n","# }\n","\n","# Perform GridSearchCV\n","grid_search = GridSearchCV(multioutput_classifier, param_grid=param_grid, scoring=scoring, cv=5, refit='F1 Micro', verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters and evaluate on the test set\n","best_params = grid_search.best_params_\n","print(\"Best parameters:\", best_params)\n","\n","y_pred = grid_search.predict(X_test)\n","# Evaluate on the test set\n","# Example: print classification_report(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate performance (you can use different metrics for multilabel classification)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","print(\"Training Acc: \", grid_search.score(X_train, y_train))\n","print(\"Test Acc: \", grid_search.score(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_proba = grid_search.predict_proba(X_test)\n","print(\"Prediction Probability: \", pred_proba)\n","# print(classification_report(y_test, pred_proba))"]},{"cell_type":"markdown","metadata":{},"source":["# **GradientBoostingClassifier with MultiOutputClassifer and GridSearch**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T07:02:11.957458Z","iopub.status.busy":"2023-12-05T07:02:11.957073Z","iopub.status.idle":"2023-12-05T09:01:09.453581Z","shell.execute_reply":"2023-12-05T09:01:09.452140Z","shell.execute_reply.started":"2023-12-05T07:02:11.957423Z"},"trusted":true},"outputs":[],"source":["from sklearn.datasets import make_multilabel_classification\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import make_scorer, f1_score, hamming_loss\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","# Initialize GradientBoostingClassifier\n","clf = GradientBoostingClassifier()\n","# Create MultiOutputClassifier using AdaBoost\n","multioutput_classifier = MultiOutputClassifier(clf)\n","\n","# Parameters to tune\n","params = {\n","    'estimator__n_estimators': [500, 700, 1000],\n","    'estimator__max_depth': [15, 20, 25],\n","    'estimator__learning_rate': [0.01, 0.1, 0.3]\n","}\n","\n","# # Create a scoring function\n","# scoring = {\n","#     'F1 Micro': make_scorer(f1_score, average='micro'),\n","#     'Loss': make_scorer(log_loss)\n","# }\n","\n","# Apply GridSearchCV\n","grid_search = GridSearchCV(multioutput_classifier, params, scoring=scoring, cv=5, refit='F1 Micro', verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","print(\"Best parameters:\")\n","print(grid_search.best_params_)\n","\n","# Evaluation on test set\n","y_pred = grid_search.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate performance (you can use different metrics for multilabel classification)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","print(\"Training Acc: \", grid_search.score(X_train, y_train))\n","print(\"Test Acc: \", grid_search.score(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_proba = grid_search.predict_proba(X_test)\n","print(\"Prediction Probability: \", pred_proba)\n","# print(classification_report(y_test, pred_proba))"]},{"cell_type":"markdown","metadata":{},"source":["## Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T09:01:09.455272Z","iopub.status.busy":"2023-12-05T09:01:09.454892Z","iopub.status.idle":"2023-12-05T09:01:09.461282Z","shell.execute_reply":"2023-12-05T09:01:09.459904Z","shell.execute_reply.started":"2023-12-05T09:01:09.455243Z"},"trusted":true},"outputs":[],"source":["from sklearn import decomposition, datasets\n","from sklearn import tree\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T09:01:09.463068Z","iopub.status.busy":"2023-12-05T09:01:09.462688Z","iopub.status.idle":"2023-12-05T09:01:09.476727Z","shell.execute_reply":"2023-12-05T09:01:09.474947Z","shell.execute_reply.started":"2023-12-05T09:01:09.463037Z"},"trusted":true},"outputs":[],"source":["std_slc = StandardScaler()\n","pca = decomposition.PCA()\n","dec_tree = tree.DecisionTreeClassifier()\n","pipe = Pipeline(steps=[('std_slc', std_slc),\n","                           ('pca', pca),\n","                           ('dec_tree', dec_tree)])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T09:01:09.483544Z","iopub.status.busy":"2023-12-05T09:01:09.483200Z","iopub.status.idle":"2023-12-05T09:01:09.494536Z","shell.execute_reply":"2023-12-05T09:01:09.492771Z","shell.execute_reply.started":"2023-12-05T09:01:09.483508Z"},"trusted":true},"outputs":[],"source":["n_components = list(range(1, X_train.shape[1]+1, 1))\n","criterion = ['gini', 'entropy']\n","max_depth = [2,4,6,8,10,12]\n","parameters = dict(pca__n_components=n_components,\n","                      dec_tree__criterion=criterion,\n","                      dec_tree__max_depth=max_depth)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T09:01:09.498462Z","iopub.status.busy":"2023-12-05T09:01:09.498051Z"},"trusted":true},"outputs":[],"source":["clf_GS = GridSearchCV(pipe, parameters)\n","clf_GS.fit(X_train, y_train)\n","dtPreds = clf_GS.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cr = classification_report(y_test, dtPreds)\n","print(cr) \n","# write_log(\"DecisionTree-Grid\", cr)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# pickle = pkl.dump(dtClassifier, open(os.path.join(pkl_file, 'decision_tree.pickle'), 'wb'))"]},{"cell_type":"markdown","metadata":{},"source":["## TabNetClassification"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pytorch_tabnet.tab_model import TabNetClassifier\n","\n","# Initialize TabNetClassifier model\n","clf = TabNetClassifier()  # You can set various parameters here\n","\n","# Fit the model on the training data\n","clf.fit(\n","    X_train=X_train.values,\n","    y_train=y_train,\n","    eval_set=[(X_test.values, y_test)],\n","    patience=10,  # Early stopping patience\n","    max_epochs=100  # Maximum number of training epochs\n",")\n","\n","# Predict on test data\n","y_pred_proba = clf.predict_proba(X_test.values)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred_proba"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4070501,"sourceId":7068668,"sourceType":"datasetVersion"},{"datasetId":4109249,"sourceId":7123742,"sourceType":"datasetVersion"},{"datasetId":4132934,"sourceId":7156455,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
