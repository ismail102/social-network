,Batch,Max Token,Model,LR,Loss func,Epoch,Train Loss,Valid. Loss,Valid. AUC,F1 score,Recall,Precision,Accuracy
0,16,30,roberta-large,2e-05,bce_loss,1,0.15902290357049798,0.13139846785309836,0.9743562345989023,0.8762126696279291,0.848384142736563,0.9122790952264354,0.9403439926525842
1,16,30,roberta-large,2e-05,bce_loss,2,0.11599014079935215,0.12696912008986122,0.9759679892748289,0.8873995418602799,0.865268901763471,0.9143080294870932,0.9446960841613091
2,16,30,roberta-large,2e-05,bce_loss,3,0.09387794905116716,0.11955595744564851,0.9786001425070654,0.8803050086895883,0.8518018086504733,0.9173588665999892,0.942379143358103
3,16,70,roberta-large,2e-05,bce_loss,1,0.15932982916802244,0.12484948858537914,0.9754403372920059,0.8764579195337385,0.8479938898429106,0.9135765855259453,0.9405735993988478
4,16,70,roberta-large,2e-05,bce_loss,2,0.1130902952057479,0.116482437890115,0.9778323613406037,0.880833240277448,0.8520084024601089,0.9184073043556855,0.9426818067963597
5,16,70,roberta-large,2e-05,bce_loss,3,0.09253192442688525,0.11518396651798185,0.9806437536221353,0.8830551668674756,0.8544554242380402,0.9201784738713764,0.9436837271436921
6,16,30,roberta-large,2e-05,bce_loss,1,0.15806667714415487,0.12834511622376193,0.9739845014084715,0.8835899956643729,0.860335468021028,0.9122396633129123,0.9430470902563246
7,16,30,roberta-large,2e-05,bce_loss,2,0.1154883870062028,0.12622217258742485,0.9755596978610958,0.8779642818161633,0.8491148143240401,0.9156792015343884,0.9413459129999165
8,16,30,roberta-large,2e-05,bce_loss,3,0.09321496405868863,0.12368708764462767,0.9770250329347305,0.8828564583077438,0.8542614848767063,0.9199783962953472,0.9435897971111297
9,16,70,roberta-large,2e-05,bce_loss,1,0.15443516673709892,0.12422312181896825,0.9771446136283997,0.8733018801961769,0.845001592331919,0.9102542685068579,0.9390707188778492
10,16,70,roberta-large,2e-05,bce_loss,2,0.11036684944765496,0.11627674740658345,0.9787323358796666,0.8803926460092333,0.8529119791896311,0.9157541301557585,0.9422434666444017
11,16,70,roberta-large,2e-05,bce_loss,3,0.08882108606376339,0.11090850886156427,0.9812974488555368,0.8845650367216704,0.8558285020513188,0.9218660603583391,0.944414294063622
12,16,30,roberta-large,2e-05,bce_loss,1,0.16052235422643502,0.1262232557092066,0.9728841650497604,0.8749509708371686,0.8471466324255852,0.9110184542348334,0.9397491024463556
13,16,30,roberta-large,2e-05,bce_loss,2,0.1150039475439163,0.11647502843474594,0.9780575700876243,0.8782978941922235,0.8486785282432199,0.917308533391169,0.9416381397678885
14,16,30,roberta-large,2e-05,bce_loss,3,0.09736887829250754,0.12634340041125558,0.9746084973668004,0.8797696009689883,0.8523455055013518,0.9150575688635298,0.9419408032061451
15,16,70,roberta-large,2e-05,bce_loss,1,0.1565993378299579,0.13753033781210297,0.9709077721285725,0.8732562408643194,0.8461823155137571,0.908170982283012,0.9388202387910161
16,16,70,roberta-large,2e-05,bce_loss,2,0.11363016585158635,0.1110798247082057,0.9808389682023321,0.8873311398635026,0.8603856063018684,0.9216243414984815,0.945426651081239
17,16,70,roberta-large,2e-05,bce_loss,3,0.09324439618151903,0.1174870358989232,0.9791402254720611,0.8854515923359887,0.8572162927074473,0.921894595002948,0.9447482675127328
