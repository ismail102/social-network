,Batch,Max Token,Model,LR,Loss func,Epoch,Train Loss,Valid. Loss,Valid. AUC,F1 score,Recall,Precision,Accuracy
0,16,30,roberta-large,2e-05,bce_loss,1,0.22995959247879402,0.19043050221413574,0.9509651728351618,0.7941538948854883,0.756517049199976,0.8651339734946333,0.8879003558718861
1,16,30,roberta-large,2e-05,bce_loss,2,0.16577591429070948,0.17276873274777943,0.9561399646929016,0.8053664293816915,0.7665439340475209,0.8775582573516912,0.8938141092736027
2,16,30,roberta-large,2e-05,bce_loss,3,0.1341981409016264,0.19177695198987538,0.9534870291289609,0.8030763499198937,0.7636913847459041,0.87766224412235,0.8930029307096504
3,16,70,roberta-large,2e-05,bce_loss,1,0.2150102812874766,0.15969787820874648,0.9616157453132093,0.8096341754634537,0.7691536913201189,0.8862356783913616,0.8966401507222106
4,16,70,roberta-large,2e-05,bce_loss,2,0.14867581368178504,0.15631353644105953,0.9634724680008038,0.8089192299011785,0.7688276185406745,0.8844079193226321,0.8961168097132092
5,16,70,roberta-large,2e-05,bce_loss,3,0.11771957621788878,0.1618364919350797,0.9646708221851694,0.8179159626011259,0.7784123957007745,0.8895077809235901,0.9001988695834205
6,16,30,roberta-large,3e-05,bce_loss,1,0.23219638531365155,0.2097521831521322,0.9410759142012833,0.808294591347329,0.7715153688970044,0.873564158341932,0.8942589491312539
7,16,30,roberta-large,3e-05,bce_loss,2,0.17006925957347557,0.19067897346107457,0.9549562466317045,0.8126960476787954,0.7760320644108305,0.8768293687515409,0.8963784802177098
8,16,30,roberta-large,3e-05,bce_loss,3,0.13824341494169196,0.18270543952593984,0.955679106092643,0.8145566833894355,0.7769634281470723,0.8810598654049108,0.8977129997906635
9,16,30,roberta-large,2e-05,bce_loss,1,0.23234715698029706,0.1827985949185132,0.9511943072185497,0.8053135384583539,0.7672482218751946,0.8751068470693835,0.8934216035168516
10,16,30,roberta-large,2e-05,bce_loss,2,0.1664270778237277,0.17696869943951285,0.9557259434147779,0.8172509758015387,0.7805130681744742,0.8808136713714373,0.8986811806573163
11,16,30,roberta-large,2e-05,bce_loss,3,0.13621384923396998,0.18238229943707238,0.9566040892049416,0.8176127881977996,0.7804416846741093,0.8823448576961282,0.8990475193636174
12,16,70,roberta-large,2e-05,bce_loss,1,0.21252176158098995,0.1639203218568777,0.9595056423032412,0.8172241248983212,0.7777846321605288,0.8887623287326701,0.8998325308771196
13,16,70,roberta-large,2e-05,bce_loss,2,0.14710004995012008,0.1603702824503607,0.959391639950126,0.8111277857374984,0.7711114499134585,0.8858405540547334,0.897137324680762
14,16,70,roberta-large,2e-05,bce_loss,3,0.11837929235264721,0.15586110382001336,0.964918152362768,0.8290570238482018,0.7909149367183801,0.8946120633973905,0.9051967762193845
15,16,30,roberta-large,3e-05,bce_loss,1,0.23345889166683334,0.18027028854450453,0.9514817355352422,0.7976182569209633,0.7582483194032692,0.873566597935369,0.8904385597655432
16,16,30,roberta-large,3e-05,bce_loss,2,0.1723176488535923,0.17761269437902946,0.9536297874897122,0.8118303922239946,0.7732965781746269,0.8816988870074021,0.896797153024911
17,16,30,roberta-large,3e-05,bce_loss,3,0.1414392957565176,0.18722021555135582,0.9560656867998204,0.8045231704777094,0.7657337460063429,0.8768036685198752,0.8933954364664015
