,Batch,Max Token,Model,LR,Loss func,Test. Loss,Test. AUC,F1 score,Recall,Precision,Accuracy
0,16,30,roberta-large,2e-05,bce_loss,0.12045662105083466,0.9776882995621778,0.8807130275186903,0.8526142234987902,0.917069278409191,0.9425973548861132
1,16,70,roberta-large,2e-05,bce_loss,0.11791162192821503,0.9792575962948549,0.8831531300681108,0.8547013741051916,0.9200148952237946,0.943799679380135
2,16,30,roberta-large,2e-05,bce_loss,0.12351418286561966,0.9769283975775478,0.8820270196365139,0.8535689730799643,0.9189360153949937,0.9432736624140003
3,16,70,roberta-large,2e-05,bce_loss,0.11402212828397751,0.9801845429837229,0.88316791375816,0.8548074645329515,0.9198779583349426,0.943791329904482
4,16,30,roberta-large,2e-05,bce_loss,0.12998001277446747,0.973366533093958,0.8762893464073408,0.8490369696155575,0.9113912627118121,0.940376394362434
5,16,70,roberta-large,2e-05,bce_loss,0.12794817984104156,0.9763009171605528,0.8814620645509652,0.853657824509457,0.9173091831618483,0.9428979360096186
