,Batch,Max Token,Model,LR,Loss func,Test. Loss,Test. AUC,F1 score,Recall,Precision,Accuracy
0,16,30,roberta-large,2e-05,bce_loss,0.197727769613266,0.954080432786166,0.7985685411064516,0.7600383098204926,0.8713982347218878,0.8904915424552001
1,16,70,roberta-large,2e-05,bce_loss,0.17130611836910248,0.9633656030999481,0.813383363468072,0.7744533958986948,0.8841245702768614,0.8977767543125105
2,16,30,roberta-large,3e-05,bce_loss,0.18964576721191406,0.9547193262921798,0.8136412896184221,0.7766360402266863,0.8785710260833705,0.8970440462234132
3,16,30,roberta-large,2e-05,bce_loss,0.19260558485984802,0.9544097620163668,0.8100457242572281,0.773826307423171,0.8733419417000456,0.8949087255066153
4,16,70,roberta-large,2e-05,bce_loss,0.16618773341178894,0.9634258191289355,0.8229444427452695,0.7856474513993119,0.8871152461578051,0.9018171160609613
5,16,30,roberta-large,3e-05,bce_loss,0.19387777149677277,0.9544491135011317,0.8012862531010776,0.7631825821119539,0.8720735503532182,0.891559202813599
