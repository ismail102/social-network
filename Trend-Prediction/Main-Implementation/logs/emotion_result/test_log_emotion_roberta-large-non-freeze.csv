,Batch,Max Token,Model,LR,Loss func,Test. Loss,Test. AUC,F1 score,Recall,Precision,Accuracy
0,16,30,roberta-large,2e-05,bce_loss,0.10031349956989288,0.9202929253058123,0.7501246032444187,0.7212883587481067,0.7890584761819968,0.9643926679172015
1,16,70,roberta-large,2e-05,bce_loss,0.10022222250699997,0.9215945659686768,0.7521046401194207,0.7231540328230663,0.7911323463808675,0.9646559383947083
2,16,30,roberta-large,2e-05,bce_loss,0.1001162976026535,0.9214732410884039,0.7521759983975156,0.7235083845330045,0.7906893645397887,0.9646189159838089
3,16,30,roberta-large,2e-05,bce_loss,0.10007749497890472,0.9229148841182934,0.7534814660902698,0.7260580854467318,0.7897266326334731,0.9645818935729095
4,16,30,roberta-large,2e-05,bce_loss,0.10019966959953308,0.922734571395569,0.752456947048709,0.7241070200029582,0.7903863640847981,0.9646024615789647
5,16,30,roberta-large,2e-05,bce_loss,0.10043317824602127,0.9185250100537966,0.7560936989212161,0.7271060455937683,0.7949655284906829,0.9651577977424557
