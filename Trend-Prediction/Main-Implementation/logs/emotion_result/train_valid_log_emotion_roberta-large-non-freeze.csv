,Batch,Max Token,Model,LR,Loss func,Epoch,Train Loss,Valid. Loss,Valid. AUC,F1 score,Recall,Precision,Accuracy
0,16,30,roberta-large,2e-05,bce_loss,1,0.12941035521943198,0.10523448179296986,0.9046060632284503,0.7410238544668817,0.7019409227226476,0.8024010267515357,0.9651340956768542
1,16,30,roberta-large,2e-05,bce_loss,2,0.10182734843928991,0.10089718378325806,0.9200634135854954,0.746150894438314,0.7121159311418768,0.795501651879997,0.9648153099420016
2,16,30,roberta-large,2e-05,bce_loss,3,0.09249009639582348,0.09910498676720848,0.9209593137400114,0.7564804535440134,0.7268182116644728,0.7965460862708986,0.9653346221874871
3,16,70,roberta-large,2e-05,bce_loss,1,0.13146764733150354,0.10411848421492566,0.9107877838396263,0.7468503749598225,0.7141971802995701,0.7933054527617792,0.9646610587799761
4,16,70,roberta-large,2e-05,bce_loss,2,0.10169764376949426,0.10156360560528703,0.915474767683027,0.7535566424559939,0.7253941181859017,0.7910939958783176,0.964733042655588
5,16,70,roberta-large,2e-05,bce_loss,3,0.09234278895943139,0.09933839194365146,0.9216793779650215,0.7552205314881196,0.7253515775896745,0.7957373036705467,0.9652112212578668
6,16,30,roberta-large,2e-05,bce_loss,1,0.12930737277541135,0.10598312728578531,0.9024789592874102,0.7341653525186357,0.692426987047325,0.8036314884060982,0.9649284274608202
7,16,30,roberta-large,2e-05,bce_loss,2,0.10158661729776798,0.10014402234478842,0.9181766938290149,0.7498721125140738,0.7141779597199156,0.802368601054819,0.9655197235819176
8,16,30,roberta-large,2e-05,bce_loss,3,0.09228225819933805,0.09975985048383783,0.921459221342941,0.7538479675857144,0.7247869377195202,0.79297527980083,0.9649130023446176
9,16,30,roberta-large,2e-05,bce_loss,1,0.1298581453004855,0.10560007458520566,0.9068458554356879,0.7341776671105769,0.6929602556304162,0.8022249687623529,0.9648307350582042
10,16,30,roberta-large,2e-05,bce_loss,2,0.10206534387088055,0.10041355351532699,0.9183242715900195,0.7583389572350329,0.7307455555458378,0.7946456069682959,0.9652472131956727
11,16,30,roberta-large,2e-05,bce_loss,3,0.09279089466929778,0.09948435605378228,0.9220278284630172,0.7596416206052379,0.7315170618328364,0.7968061439613022,0.9654940150549134
12,16,30,roberta-large,2e-05,bce_loss,1,0.12945775787636132,0.10538623082881281,0.9067404607428067,0.7348380266339174,0.6911890889570673,0.8095371542923253,0.9653551890090906
13,16,30,roberta-large,2e-05,bce_loss,2,0.10101948365157339,0.10060820192895975,0.9211437332960737,0.7544057171342966,0.7282080677270171,0.7885066612174305,0.9645273744395542
14,16,30,roberta-large,2e-05,bce_loss,3,0.09152869427459777,0.09983946402933368,0.9219385238468346,0.7532922605218917,0.7246029918061931,0.7917818053376412,0.9647844597095965
15,16,30,roberta-large,2e-05,bce_loss,1,0.13414932332319573,0.10606904612946291,0.9032712514055414,0.745007612357012,0.7086357584841163,0.7995231800886855,0.9650878203282465
16,16,30,roberta-large,2e-05,bce_loss,2,0.10318436721960704,0.10116856327008186,0.9176803828276059,0.7464934770955298,0.7125383319000327,0.7956453884928262,0.9648410184690058
17,16,30,roberta-large,2e-05,bce_loss,3,0.09378638519129673,0.099908121073805,0.9183721449311189,0.7590079813372155,0.7297541635708997,0.7981961579941534,0.9655865657521286
