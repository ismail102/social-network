,Batch,Max Token,Model,LR,Loss func,Epoch,Train Loss,Valid. Loss,Valid. AUC,F1 score,Recall,Precision,Accuracy
0,16,30,roberta-large,2e-05,bce_loss,1,0.12631863409896726,0.09996197421545264,0.918014804119615,0.7546608985901038,0.7146494671271251,0.8162965192641229,0.9667588745835218
1,16,30,roberta-large,2e-05,bce_loss,2,0.0977269887868433,0.0957466439913071,0.9310813322301682,0.7620002809151605,0.7295569812455556,0.8068905301047663,0.9664400888486693
2,16,30,roberta-large,2e-05,bce_loss,3,0.0891205782974734,0.09473231202259368,0.9327452244000279,0.7647667791455595,0.7353459057375961,0.803946618776691,0.9663372547406524
3,16,70,roberta-large,2e-05,bce_loss,1,0.12600713764962343,0.1005450728659114,0.9200243396998449,0.757068774728602,0.7217111785482151,0.8081479094332435,0.9662961210974456
4,16,70,roberta-large,2e-05,bce_loss,2,0.0977544608254095,0.09628764560534024,0.9278776737758918,0.7638081492584339,0.7323432594234706,0.8067410143472756,0.9665172144296821
5,16,70,roberta-large,2e-05,bce_loss,3,0.08851215679565241,0.09384897482443184,0.9344826646929332,0.7691603658881487,0.7392930520838046,0.8089014641426195,0.9669594010941549
6,16,30,roberta-large,3e-05,bce_loss,1,0.15579862600094846,0.14915477399584615,0.7706387850716931,0.48938014786247575,0.5000611097531166,0.9789677459161794,0.9579357081156678
7,16,30,roberta-large,3e-05,bce_loss,2,0.15063811924413628,0.148877495237475,0.7758559998213331,0.48925531719333076,0.49999731624316984,0.4789651750502604,0.9579254247048661
8,16,30,roberta-large,3e-05,bce_loss,3,0.1505850958383214,0.14875031389527546,0.775970398318295,0.6392621429346836,0.6292957746242338,0.6512994422582675,0.9460635103451113
9,16,30,roberta-large,2e-05,bce_loss,1,0.12550341621015562,0.10114385973409212,0.9201077352620927,0.7584550998020605,0.7259482054008691,0.8037180946482663,0.9660184690057998
10,16,30,roberta-large,2e-05,bce_loss,2,0.09672528228662998,0.09591814689123863,0.9313325075313197,0.7632190112941737,0.7327536918463515,0.8043537732360282,0.9662961210974456
11,16,30,roberta-large,2e-05,bce_loss,3,0.08786119746712343,0.09456917079394925,0.9328683492067809,0.7660647800493238,0.7369293918049673,0.804676819602249,0.9664606556702727
12,16,70,roberta-large,2e-05,bce_loss,1,0.1302018112057437,0.10196650407616782,0.9137526345130739,0.7475297005394168,0.7048427848163931,0.8169382413292554,0.9664400888486693
13,16,70,roberta-large,2e-05,bce_loss,2,0.09831728995120861,0.09747031729312569,0.9253783571662617,0.7519658406294913,0.714995706527004,0.8070114874902768,0.9659670519517913
14,16,70,roberta-large,2e-05,bce_loss,3,0.08940496101597979,0.09539393866509714,0.9293850601503839,0.7636821156492297,0.7340626009221475,0.8032710997779406,0.9662292789272345
15,16,30,roberta-large,3e-05,bce_loss,1,0.12279193447532843,0.09977949157108577,0.9200769468442408,0.754732638281191,0.7175709840823686,0.8098913528785578,0.9663115462136481
16,16,30,roberta-large,3e-05,bce_loss,2,0.0976590934752663,0.09763283108042765,0.9264725348629459,0.7544018644279339,0.7225429955622195,0.7987083228392531,0.9654271728847024
17,16,30,roberta-large,3e-05,bce_loss,3,0.08971195461235996,0.09531129602990161,0.9330420311114632,0.7645488727161502,0.7368369107647876,0.8007751849984031,0.9660596026490066
