,Batch,Max Token,Model,LR,Loss func,Test. Loss,Test. AUC,F1 score,Recall,Precision,Accuracy
0,16,30,roberta-large,2e-05,bce_loss,0.10031349956989288,0.9202929253058123,0.7501246032444187,0.7212883587481067,0.7890584761819968,0.9643926679172015
1,16,70,roberta-large,2e-05,bce_loss,0.10022222250699997,0.9215945659686768,0.7521046401194207,0.7231540328230663,0.7911323463808675,0.9646559383947083
2,16,30,roberta-large,2e-05,bce_loss,0.1001162976026535,0.9214732410884039,0.7521759983975156,0.7235083845330045,0.7906893645397887,0.9646189159838089
3,16,70,roberta-large,2e-05,bce_loss,0.09969620406627655,0.9236788059360295,0.7557390448712881,0.728352734317341,0.791811587058586,0.9648616184552605
4,16,30,roberta-large,2e-05,bce_loss,0.10019966959953308,0.922734571395569,0.752456947048709,0.7241070200029582,0.7903863640847981,0.9646024615789647
5,16,70,roberta-large,2e-05,bce_loss,0.10073757916688919,0.9168348627280235,0.753465082885748,0.7247195960816422,0.7920470615508999,0.9647916872346727
