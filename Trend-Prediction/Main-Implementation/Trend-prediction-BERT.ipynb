{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:19.796764Z","iopub.status.busy":"2023-12-04T20:18:19.796403Z","iopub.status.idle":"2023-12-04T20:18:19.809669Z","shell.execute_reply":"2023-12-04T20:18:19.808396Z","shell.execute_reply.started":"2023-12-04T20:18:19.796732Z"},"trusted":true},"outputs":[],"source":["%%capture\n","# !pip install text_hammer"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-04T20:18:19.812166Z","iopub.status.busy":"2023-12-04T20:18:19.811699Z","iopub.status.idle":"2023-12-04T20:18:23.779602Z","shell.execute_reply":"2023-12-04T20:18:23.778572Z","shell.execute_reply.started":"2023-12-04T20:18:19.812129Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","import torch\n","import wandb\n","import logging\n","import transformers\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from datasets import load_dataset\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn import metrics, model_selection, preprocessing\n","from transformers import AdamW, get_linear_schedule_with_warmup"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:23.782034Z","iopub.status.busy":"2023-12-04T20:18:23.781040Z","iopub.status.idle":"2023-12-04T20:18:26.642212Z","shell.execute_reply":"2023-12-04T20:18:26.641396Z","shell.execute_reply.started":"2023-12-04T20:18:23.781994Z"},"trusted":true},"outputs":[],"source":["%%capture\n","import re\n","# import text_hammer as th\n","# from wordcloud import WordCloud\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from transformers import AutoTokenizer,TFBertModel\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\",  category = FutureWarning)\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:26.645267Z","iopub.status.busy":"2023-12-04T20:18:26.644536Z","iopub.status.idle":"2023-12-04T20:18:26.653505Z","shell.execute_reply":"2023-12-04T20:18:26.652367Z","shell.execute_reply.started":"2023-12-04T20:18:26.645238Z"},"trusted":true},"outputs":[],"source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    # Some cudnn methods can be random even after fixing the seed \n","    # unless you tell it to be deterministic\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(1234)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:26.655232Z","iopub.status.busy":"2023-12-04T20:18:26.654883Z","iopub.status.idle":"2023-12-04T20:18:26.984739Z","shell.execute_reply":"2023-12-04T20:18:26.983719Z","shell.execute_reply.started":"2023-12-04T20:18:26.655199Z"},"trusted":true},"outputs":[],"source":["# Loading datasets into DF\n","df = pd.read_csv(\"/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/DataSet/trend-data/trend_dataset_class8_reduced2.csv\")\n","\n","# Checking Shape\n","display(df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:26.986527Z","iopub.status.busy":"2023-12-04T20:18:26.986245Z","iopub.status.idle":"2023-12-04T20:18:27.006866Z","shell.execute_reply":"2023-12-04T20:18:27.005772Z","shell.execute_reply.started":"2023-12-04T20:18:26.986504Z"},"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from utils.preprocessing import expand_contractions\n","# df['text'] = df['text'].apply(expand_contractions)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.009096Z","iopub.status.busy":"2023-12-04T20:18:27.008314Z","iopub.status.idle":"2023-12-04T20:18:27.013124Z","shell.execute_reply":"2023-12-04T20:18:27.012162Z","shell.execute_reply.started":"2023-12-04T20:18:27.009058Z"},"trusted":true},"outputs":[],"source":["from utils.preprocessing import get_clean_dataset\n","df = get_clean_dataset(df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.025380Z","iopub.status.busy":"2023-12-04T20:18:27.023365Z","iopub.status.idle":"2023-12-04T20:18:27.048001Z","shell.execute_reply":"2023-12-04T20:18:27.047231Z","shell.execute_reply.started":"2023-12-04T20:18:27.025338Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","train_temp, test = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.052148Z","iopub.status.busy":"2023-12-04T20:18:27.051802Z","iopub.status.idle":"2023-12-04T20:18:27.065886Z","shell.execute_reply":"2023-12-04T20:18:27.065107Z","shell.execute_reply.started":"2023-12-04T20:18:27.052094Z"},"trusted":true},"outputs":[],"source":["train, valid = train_test_split(train_temp, test_size=0.2, shuffle=True, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.067286Z","iopub.status.busy":"2023-12-04T20:18:27.066986Z","iopub.status.idle":"2023-12-04T20:18:27.097384Z","shell.execute_reply":"2023-12-04T20:18:27.096440Z","shell.execute_reply.started":"2023-12-04T20:18:27.067260Z"},"trusted":true},"outputs":[],"source":["# train[[str(i) for i in range(0, 28)]].values.tolist()"]},{"cell_type":"markdown","metadata":{},"source":["üßπClean Data (Noise Entity Removal) ¬∂"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.099256Z","iopub.status.busy":"2023-12-04T20:18:27.098829Z","iopub.status.idle":"2023-12-04T20:18:27.105209Z","shell.execute_reply":"2023-12-04T20:18:27.104177Z","shell.execute_reply.started":"2023-12-04T20:18:27.099230Z"},"trusted":true},"outputs":[],"source":["# def text_preprocessing(df,col_name):\n","#     tqdm.pandas()\n","#     df[col_name] = df[col_name].progress_apply(lambda x:str(x).lower())\n","#     df[col_name] = df[col_name].progress_apply(lambda x: th.remove_emails(x))\n","#     df[col_name] = df[col_name].progress_apply(lambda x: th.remove_html_tags(x))\n","#     df[col_name] = df[col_name].progress_apply(lambda x: th.remove_urls(x))\n","#     df[col_name] = df[col_name].progress_apply(lambda x: th.remove_special_chars(x))\n","#     df[col_name] = df[col_name].progress_apply(lambda x: th.remove_accented_chars(x))\n","#     df[col_name] = df[col_name].progress_apply(lambda text: th.cont_exp(text))\n","#     df[col_name] = df[col_name].progress_apply(lambda x: re.sub(\"[\" \n","#         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","#         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","#         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","#         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","#         u\"\\U00002702-\\U000027B0\"\n","#         u\"\\U000024C2-\\U0001F251\"\n","#         \"]+\", \"\", x))\n","#     df[col_name] = df[col_name].progress_apply(lambda x: re.sub(r'[^a-zA-Z]', ' ', x))\n","#     df[col_name] = df[col_name].progress_apply(lambda x: ' '.join(x.split()))\n","    \n","#     return(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.107234Z","iopub.status.busy":"2023-12-04T20:18:27.106552Z","iopub.status.idle":"2023-12-04T20:18:27.117680Z","shell.execute_reply":"2023-12-04T20:18:27.116799Z","shell.execute_reply.started":"2023-12-04T20:18:27.107192Z"},"trusted":true},"outputs":[],"source":["# # %%capture\n","# train = text_preprocessing(train,'text')\n","# valid = text_preprocessing(valid,'text')\n","# test = text_preprocessing(test,'text')"]},{"cell_type":"markdown","metadata":{},"source":["üóëÔ∏èRemove Stop Words ¬∂"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.119312Z","iopub.status.busy":"2023-12-04T20:18:27.118889Z","iopub.status.idle":"2023-12-04T20:18:27.127278Z","shell.execute_reply":"2023-12-04T20:18:27.126447Z","shell.execute_reply.started":"2023-12-04T20:18:27.119277Z"},"trusted":true},"outputs":[],"source":["# stop = stopwords.words('english')\n","# train['text'] = train['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n","# valid['text'] = valid['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n","# test['text'] = test['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"]},{"cell_type":"markdown","metadata":{},"source":["üå±Lemmatization ¬∂"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.128781Z","iopub.status.busy":"2023-12-04T20:18:27.128375Z","iopub.status.idle":"2023-12-04T20:18:27.136140Z","shell.execute_reply":"2023-12-04T20:18:27.135188Z","shell.execute_reply.started":"2023-12-04T20:18:27.128755Z"},"trusted":true},"outputs":[],"source":["# nltk.download('wordnet')\n","# !unzip \"/usr/share/nltk_data/corpora/wordnet.zip\" -d \"/usr/share/nltk_data/corpora/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.137637Z","iopub.status.busy":"2023-12-04T20:18:27.137351Z","iopub.status.idle":"2023-12-04T20:18:27.144847Z","shell.execute_reply":"2023-12-04T20:18:27.143738Z","shell.execute_reply.started":"2023-12-04T20:18:27.137613Z"},"trusted":true},"outputs":[],"source":["# def word_lemmatizer(text):\n","#     lemmatizer = WordNetLemmatizer()\n","#     return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n","\n","# train['text'] = train['text'].apply(lambda text: word_lemmatizer(text))\n","# valid['text'] = valid['text'].apply(lambda text: word_lemmatizer(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.182002Z","iopub.status.busy":"2023-12-04T20:18:27.181686Z","iopub.status.idle":"2023-12-04T20:18:27.194021Z","shell.execute_reply":"2023-12-04T20:18:27.192911Z","shell.execute_reply.started":"2023-12-04T20:18:27.181978Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","from utils.dataset import Dataset\n","\n","def build_dataset(tokenizer_max_len, tokenizer):\n","    train_dataset = Dataset(train.text.tolist(), train[get_classes()].values.tolist(), tokenizer, tokenizer_max_len)\n","    valid_dataset = Dataset(valid.text.tolist(), valid[get_classes()].values.tolist(), tokenizer, tokenizer_max_len)\n","    test_dataset = Dataset(test.text.tolist(), test[get_classes()].values.tolist(), tokenizer, tokenizer_max_len)\n","\n","    return train_dataset, valid_dataset, test_dataset\n","    # return train_dataset, valid_dataset\n","\n","def build_dataloader(train_dataset, valid_dataset, test_dataset, batch_size):\n","    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","    valid_data_loader = DataLoader(valid_dataset, batch_size=int(batch_size/2), shuffle=True, num_workers=1)\n","    test_data_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True, num_workers=1)\n","\n","    return train_data_loader, valid_data_loader, test_data_loader\n","    # return train_data_loader, valid_data_loader\n","\n","def ret_model(do_prob, model_ckpt, n_labels, is_freeze):\n","    # model = TextClassification(n_classes=n_labels, dropout=do_prob, model_ckpt=model_ckpt)\n","    model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=n_labels)\n","\n","    if model_ckpt != 'roberta-large' and is_freeze == True:\n","        # Freeze all layers except the classification layer\n","        for param in model.base_model.parameters():\n","            param.requires_grad = False\n","\n","        # Modify the classification layer for the new task (target domain)\n","        model.classifier = torch.nn.Linear(model.classifier.in_features, n_labels)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.195699Z","iopub.status.busy":"2023-12-04T20:18:27.195397Z","iopub.status.idle":"2023-12-04T20:18:27.203501Z","shell.execute_reply":"2023-12-04T20:18:27.202589Z","shell.execute_reply.started":"2023-12-04T20:18:27.195667Z"},"trusted":true},"outputs":[],"source":["def ret_optimizer(model):\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\"]\n","    optimizer_parameters = [\n","        {\n","            \"params\": [\n","                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n","            ],\n","            \"weight_decay\": 0.001,\n","        },\n","        {\n","            \"params\": [\n","                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n","            ],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","    # opt = AdamW(optimizer_parameters, lr=wandb.config.learning_rate)\n","    opt = AdamW(model.parameters(), lr=wandb.config.learning_rate)\n","    return opt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.205109Z","iopub.status.busy":"2023-12-04T20:18:27.204749Z","iopub.status.idle":"2023-12-04T20:18:27.215226Z","shell.execute_reply":"2023-12-04T20:18:27.214300Z","shell.execute_reply.started":"2023-12-04T20:18:27.205077Z"},"trusted":true},"outputs":[],"source":["def ret_scheduler(optimizer, num_train_steps):\n","    scheduler  = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n","    return scheduler "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.216787Z","iopub.status.busy":"2023-12-04T20:18:27.216454Z","iopub.status.idle":"2023-12-04T20:18:27.225632Z","shell.execute_reply":"2023-12-04T20:18:27.224589Z","shell.execute_reply.started":"2023-12-04T20:18:27.216759Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","def loss_fn(y_pred, y_true, loss_func, alpha=0.25, gamma=2.0):\n","    \n","    if y_true is None:\n","        return None\n","    \n","    if loss_func == 'cross_entropy':\n","        return F.cross_entropy(y_pred, y_true.float())\n","    if loss_func == 'focal_loss':\n","        logpt = -F.binary_cross_entropy_with_logits(y_pred, y_true.float())\n","        pt = torch.exp(logpt)\n","        loss = -((1 - pt) ** gamma) * logpt\n","        return loss.mean()\n","    if loss_func == 'hinge_loss':\n","        return F.hinge_embedding_loss(y_pred, y_true.float())\n","    if loss_func == 'mse_loss':\n","         return nn.MSELoss()(y_pred, y_true.float())\n","    \n","    if loss_func == 'multi_label_soft_margin':\n","        return nn.MultiLabelSoftMarginLoss()(y_pred, y_true.float())\n","    \n","    # if not all others\n","    return nn.BCEWithLogitsLoss()(y_pred, y_true.float())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.237045Z","iopub.status.busy":"2023-12-04T20:18:27.236723Z","iopub.status.idle":"2023-12-04T20:18:27.255078Z","shell.execute_reply":"2023-12-04T20:18:27.254066Z","shell.execute_reply.started":"2023-12-04T20:18:27.237008Z"},"trusted":true},"outputs":[],"source":["def train_fn(data_loader, model, optimizer, device, scheduler):\n","    train_loss = 0.0\n","    model.train()\n","    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n","        ids = d[\"ids\"]\n","        mask = d[\"mask\"]\n","        targets = d[\"labels\"]\n","        # token_type_ids = d['token_type_ids']\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        targets = targets.to(device, dtype=torch.float)\n","        \n","        optimizer.zero_grad()\n","        torch.cuda.empty_cache()\n","        outputs = model(ids, attention_mask=mask, labels=targets)\n","        # outputs = model(ids, attention_mask=mask)\n","        # loss = outputs.loss\n","\n","        loss = loss_fn(y_pred=outputs.logits, y_true=targets, \n","                           loss_func=get_loss_func())\n","        # loss = loss_fn(y_pred=outputs, y_true=targets, \n","        #                    loss_func=get_loss_func())\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        train_loss += loss.item()\n","        \n","    return train_loss\n","    \n","\n","def eval_fn(data_loader, model, device):\n","    eval_loss = 0.0\n","    model.eval()\n","    fin_targets = []\n","    fin_outputs = []\n","    val_accuracy = 0\n","    with torch.no_grad():\n","        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n","            ids = d[\"ids\"]\n","            mask = d[\"mask\"]\n","            targets = d[\"labels\"]\n","            # token_type_ids = d['token_type_ids']\n","\n","            ids = ids.to(device, dtype=torch.long)\n","            mask = mask.to(device, dtype=torch.long)\n","            targets = targets.to(device, dtype=torch.float)\n","\n","            outputs = model(ids, attention_mask=mask, labels=targets)\n","            # outputs = model(ids, attention_mask=mask)\n","            loss = loss_fn(y_pred=outputs.logits, y_true=targets, \n","                           loss_func=get_loss_func())\n","            # loss = loss_fn(y_pred=outputs, y_true=targets, \n","            #                loss_func=get_loss_func())\n","\n","            eval_loss += loss.item()\n","            \n","            fin_targets.extend(targets)\n","            fin_outputs.extend(torch.nn.functional.softmax(outputs.logits))\n","            \n","    return eval_loss, fin_outputs, fin_targets\n","\n","def test_fn(data_loader, model, device):\n","    test_loss = 0.0\n","    model.eval()\n","    fin_targets = []\n","    fin_outputs = []\n","    test_acc = 0\n","    with torch.no_grad():\n","        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n","            ids = d[\"ids\"]\n","            mask = d[\"mask\"]\n","            targets = d[\"labels\"]\n","            # token_type_ids = d['token_type_ids']\n","\n","            ids = ids.to(device, dtype=torch.long)\n","            mask = mask.to(device, dtype=torch.long)\n","            targets = targets.to(device, dtype=torch.float)\n","\n","            outputs = model(ids, attention_mask=mask, labels=targets)\n","            # outputs = model(ids, attention_mask=mask)\n","            loss = loss_fn(y_pred=outputs.logits, y_true=targets, \n","                           loss_func=get_loss_func())\n","            # loss = loss_fn(y_pred=outputs, y_true=targets, \n","            #                loss_func=get_loss_func())\n","#             logits = outputs.logits\n","            \n","            test_loss += loss.item()\n","            \n","            fin_targets.extend(targets)\n","            fin_outputs.extend(torch.nn.functional.softmax(outputs.logits))\n","\n","    return test_loss, fin_outputs, fin_targets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.256507Z","iopub.status.busy":"2023-12-04T20:18:27.256233Z","iopub.status.idle":"2023-12-04T20:18:27.266033Z","shell.execute_reply":"2023-12-04T20:18:27.265269Z","shell.execute_reply.started":"2023-12-04T20:18:27.256484Z"},"trusted":true},"outputs":[],"source":["# n_labels = 8\n","def model_info(model_ckpt):\n","    tokenizer = transformers.AutoTokenizer.from_pretrained(model_ckpt, do_lower_case=True)\n","    bert_model = transformers.AutoModel.from_pretrained(model_ckpt)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    return bert_model, tokenizer, device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.267392Z","iopub.status.busy":"2023-12-04T20:18:27.267073Z","iopub.status.idle":"2023-12-04T20:18:27.275065Z","shell.execute_reply":"2023-12-04T20:18:27.274177Z","shell.execute_reply.started":"2023-12-04T20:18:27.267369Z"},"trusted":true},"outputs":[],"source":["# using time module\n","import time\n","from datetime import datetime  \n","\n","current_time = datetime.now()\n","time_stamp = current_time.timestamp()\n","\n","date_time = datetime.fromtimestamp(time_stamp)\n","str_date_time = date_time.strftime(\"%d_%m_%Y-%H_%M_%S\")\n","\n","# dir = './bert_model_save'\n","output_dir = './model_save/trend_pred/BERT/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.276508Z","iopub.status.busy":"2023-12-04T20:18:27.276209Z","iopub.status.idle":"2023-12-04T20:18:27.289238Z","shell.execute_reply":"2023-12-04T20:18:27.288302Z","shell.execute_reply.started":"2023-12-04T20:18:27.276484Z"},"trusted":true},"outputs":[],"source":["from utils.common_functions import log_metrics\n","\n","training_stats = []\n","test_stats = []\n","def trainer(config=None):\n","    with wandb.init(config=config):\n","        config = wandb.config\n","\n","        _, tokenizer, device = model_info(get_model_ckpt())\n","\n","        train_dataset, valid_dataset, test_dataset = build_dataset(config.tokenizer_max_len, tokenizer)\n","        train_data_loader, valid_data_loader, test_data_loader = build_dataloader(train_dataset, valid_dataset, test_dataset, config.batch_size)\n","        \n","        print(\"Length of Train Dataloader: \", len(train_data_loader))\n","        print(\"Length of Valid Dataloader: \", len(valid_data_loader))\n","#         print(\"Length of Test Dataloader: \", len(test_data_loader))\n","\n","        n_train_steps = int(len(train_dataset) / config.batch_size * 10)\n","\n","        model = ret_model(config.dropout, get_model_ckpt(), get_n_labels(), get_Freeze())\n","        optimizer = ret_optimizer(model)\n","        scheduler = ret_scheduler(optimizer, n_train_steps)\n","        model.to(device)\n","        model = nn.DataParallel(model)\n","        wandb.watch(model)\n","        \n","        n_epochs = config.epochs\n","\n","        best_val_loss = 100\n","        for epoch in tqdm(range(n_epochs)):\n","            train_loss = train_fn(train_data_loader, model, optimizer, device, scheduler)\n","            eval_loss, preds, labels = eval_fn(valid_data_loader, model, device)\n","          \n","            metrics = log_metrics(preds, labels)\n","            \n","            avg_train_loss, avg_val_loss = train_loss / len(train_data_loader), eval_loss / len(valid_data_loader)\n","\n","            wandb.log({\n","                \"epoch\": epoch + 1,\n","                \"train_loss\": avg_train_loss,\n","                \"val_loss\": avg_val_loss,\n","                \"auc_score\": metrics['auc'],\n","            })\n","\n","            print(\"AUC score: \", metrics['auc'])\n","            print(\"Average Train loss: \", avg_train_loss)\n","            print(\"Average Valid loss: \", avg_val_loss)\n","            print(\"Valid F1: \", metrics['f1'])\n","            print(\"Valid Recall: \", metrics['recall'])\n","            print(\"Valid Precision: \", metrics['precision'])\n","            print(\"Valid Acc: \", metrics['acc'])\n","\n","            training_stats.append(\n","            {\n","                'Batch': config.batch_size,\n","                'Max Token': config.tokenizer_max_len,\n","                'Model':  get_model_ckpt(),\n","                'LR': config.learning_rate,\n","                'Loss func': get_loss_func(),\n","                'Epoch': epoch + 1,\n","                'Train Loss': avg_train_loss,\n","                'Valid. Loss': avg_val_loss,\n","                'Valid. AUC': metrics['auc'],\n","                'F1 score': metrics['f1'],\n","                'Recall': metrics['recall'],\n","                'Precision': metrics['precision'],\n","                'Accuracy': metrics['acc']\n","            })\n","\n","            if avg_val_loss < best_val_loss:\n","                best_val_loss = avg_val_loss\n","                torch.save(model, output_dir+f\"best_{get_type()}_{get_model_ckpt()}-{str(str_date_time)}.pt\")\n","                tokenizer.save_pretrained(output_dir)\n","                print(\"Model saved as current val_loss is: \", best_val_loss)\n","        \n","        test_loss, preds, labels = test_fn(test_data_loader, model, device)\n","        metrics = log_metrics(preds, labels)\n","        avg_test_loss = test_loss / len(test_data_loader)\n","        print(\"Test loss: \", avg_test_loss)\n","        print(\"AUC: \", metrics['auc'])\n","        print(\"Test F1: \", metrics['f1'])\n","        print(\"Test Recall: \", metrics['recall'])\n","        print(\"Test Precision: \", metrics['precision'])\n","        print(\"Test Acc: \", metrics['acc'])\n","        test_stats.append({\n","                    'Batch': config.batch_size,\n","                    'Max Token': config.tokenizer_max_len,\n","                    'Model':  get_model_ckpt(),\n","                    'LR': config.learning_rate,\n","                    'Loss func': get_loss_func(),\n","                    'Test. Loss': avg_test_loss,\n","                    'Test. AUC': metrics['auc'],\n","                    'F1 score': metrics['f1'],\n","                    'Recall': metrics['recall'],\n","                    'Precision': metrics['precision'],\n","                    'Accuracy': metrics['acc']\n","                })"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.295050Z","iopub.status.busy":"2023-12-04T20:18:27.294769Z","iopub.status.idle":"2023-12-04T20:18:27.301123Z","shell.execute_reply":"2023-12-04T20:18:27.300284Z","shell.execute_reply.started":"2023-12-04T20:18:27.295027Z"},"trusted":true},"outputs":[],"source":["def get_project():\n","    return 'trend-prediction'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:27.302433Z","iopub.status.busy":"2023-12-04T20:18:27.302097Z","iopub.status.idle":"2023-12-04T20:18:30.214955Z","shell.execute_reply":"2023-12-04T20:18:30.213932Z","shell.execute_reply.started":"2023-12-04T20:18:27.302409Z"},"trusted":true},"outputs":[],"source":["sweep_config = {\n","    'method': 'grid', #grid, random, bayesian\n","    'metric': {\n","      'name': 'auc_score',\n","      'goal': 'maximize'   \n","    },\n","    'parameters': {\n","\n","        'learning_rate': {\n","            'values': [2e-05]\n","        },\n","        'batch_size': {\n","            'values': [16]\n","        },\n","        'epochs':{'value': 3},\n","        'dropout':{\n","            'values': [0.3]\n","        },\n","        'tokenizer_max_len': {'values': [30]},\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=get_project())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:30.216763Z","iopub.status.busy":"2023-12-04T20:18:30.216184Z","iopub.status.idle":"2023-12-04T20:18:30.224282Z","shell.execute_reply":"2023-12-04T20:18:30.223230Z","shell.execute_reply.started":"2023-12-04T20:18:30.216736Z"},"trusted":true},"outputs":[],"source":["def get_Freeze():\n","    return False\n","\n","def get_model_ckpt():\n","    #  return \"bsingh/roberta_goEmotion\"\n","    #  return 'distilbert-base-uncased'\n","     return 'bert-large-uncased'\n","    # return 'bert-base-uncased'\n","    # return 'cardiffnlp/twitter-roberta-base-emotion-multilabel-latest'\n","    #  return 'roberta-large'\n","\n","def get_loss_func():\n","    # return 'hinge_loss'\n","    # return 'focal_loss'\n","    # return 'cross_entropy'\n","    # return 'mse_loss'\n","    # return 'multi_label_soft_margin'\n","    return 'bce_loss'\n","\n","def get_classes():\n","    trends = [\"approval\",\"toxic\",\"obscene\", 'insult', \"threat\", \"hate\", \"offensive\", \"neither\"]\n","    emotions = [\n","    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n","    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n","    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n","    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n","    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n","    ]\n","    return trends\n","#     return emotions\n","def get_n_labels():\n","    return len(get_classes())\n","\n","def get_type():\n","    return 'trend'\n","#     return 'emotion'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T20:18:30.225821Z","iopub.status.busy":"2023-12-04T20:18:30.225530Z"},"trusted":true},"outputs":[],"source":["# run the sweep\n","wandb.agent(sweep_id, function=trainer, count=1)"]},{"cell_type":"markdown","metadata":{},"source":["## Print the Training loss, Validation loss and AUC values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","# pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","# df_stats = df_stats.set_index('Epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_stats.to_csv('/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/logs/trend_result/train_valid_log_trend_bert_base_non_freeze.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","# pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=test_stats)\n","\n","# Use the 'epoch' as the row index.\n","# df_stats = df_stats.set_index('Epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_stats.to_csv('/home/siu856533724/code/source-code/Social-Networks/Trend-Prediction/Main-Implementation/logs/trend_result/test_log_trend_bert_base_non_freeze.csv')"]},{"cell_type":"markdown","metadata":{},"source":["## Test BERT model using unknown data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from utils.bert_classifier import get_model_tokenizer, Tokenize, Classification\n","# # Test sentiment prediction\n","# test_text = \"I love you\"\n","# model, tokenizer = get_model_tokenizer(pred_type='trend_pred', mode_pt_file='best_trend_bert-base-uncased-11_12_2023-14_25_42.pt', \n","#                                        model_ckpt='bert-base-uncased', labels=8, is_freez=1, gpu='cuda')\n","# dict = Tokenize(text=test_text, max_length=30, tokenizer=tokenizer)\n","# scores = Classification(dict, model, gpu='cuda')\n","# print(f\"Predicted Outputs: {scores}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4070501,"sourceId":7068668,"sourceType":"datasetVersion"},{"datasetId":4070714,"sourceId":7069029,"sourceType":"datasetVersion"},{"datasetId":4108867,"sourceId":7123201,"sourceType":"datasetVersion"},{"datasetId":4108871,"sourceId":7123207,"sourceType":"datasetVersion"},{"datasetId":4108888,"sourceId":7123228,"sourceType":"datasetVersion"},{"datasetId":4109249,"sourceId":7123742,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
